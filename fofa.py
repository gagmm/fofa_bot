import os
import logging
import json
import re
from datetime import datetime
from functools import wraps
from telegram import Update, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Updater,
    CommandHandler,
    MessageHandler,
    Filters,
    CallbackContext,
    ConversationHandler,
    CallbackQueryHandler
)
import traceback
import asyncio
import glob
import zipfile
import tempfile
import math

# --- å…¨å±€å˜é‡å’Œé…ç½® ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
DEFAULT_CONFIG = {
    "bot_token": "YOUR_BOT_TOKEN_HERE",
    "apis": [],
    "admins": [],
    "proxy": "",
    "proxies": [],
    "full_mode": False,
    "public_mode": False,
    "presets": [],
    "update_url": "",
    "upload_api_url": "",
    "upload_api_token": "",
    "show_download_links": True  # æ–°å¢: æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºä¸‹è½½é“¾æ¥
}

# --- æ—¥å¿—è®°å½• ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- è¾…åŠ©å‡½æ•° ---
def load_json_file(filename, default_data):
    """åŠ è½½JSONæ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºåˆ™åˆ›å»ºå¹¶ä½¿ç”¨é»˜è®¤æ•°æ®"""
    if os.path.exists(filename) and os.path.getsize(filename) > 0:
        with open(filename, 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except json.JSONDecodeError:
                return default_data
    else:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(default_data, f, indent=4)
        return default_data

def save_json_file(filename, data):
    """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4)

def escape_markdown_v2(text: str) -> str:
    """è½¬ä¹‰MarkdownV2ç‰¹æ®Šå­—ç¬¦"""
    if not isinstance(text, str):
        text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)

async def send_file_safely(update: Update, context: CallbackContext, filepath: str):
    """
    å®‰å…¨åœ°å‘é€æ–‡ä»¶ï¼Œå¤„ç†å¤§å°é™åˆ¶ã€‚
    ç­–ç•¥ï¼š
    1. å°è¯•ç›´æ¥å‘é€ã€‚
    2. å¦‚æœå¤±è´¥ (è¿‡å¤§)ï¼Œå°è¯•å‹ç¼©åå‘é€ã€‚
    3. å¦‚æœå‹ç¼©åä»è¿‡å¤§ï¼Œè¿›è¡Œåˆ†å·å‹ç¼©å‘é€ã€‚
    """
    if not os.path.exists(filepath):
        await update.message.reply_text("â›”ï¸ ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        return

    file_size = os.path.getsize(filepath)
    max_size = 50 * 1024 * 1024  # Telegram APIé™åˆ¶ (50 MB)
    chat_id = update.effective_chat.id
    base_filename = os.path.basename(filepath)

    try:
        # ç­–ç•¥1: ç›´æ¥å‘é€
        if file_size <= max_size:
            logger.info(f"æ–‡ä»¶å¤§å° ({file_size} bytes) åœ¨é™åˆ¶å†…ï¼Œå°è¯•ç›´æ¥å‘é€ {filepath}")
            await context.bot.send_document(chat_id, document=open(filepath, 'rb'), connect_timeout=60, read_timeout=60)
            return
        
        # ç­–ç•¥2: å‹ç¼©åå‘é€
        with tempfile.NamedTemporaryFile(suffix=".zip", delete=False) as tmp_zip_file:
            zip_path = tmp_zip_file.name
        
        logger.info(f"æ–‡ä»¶è¿‡å¤§ï¼Œå°è¯•å‹ç¼©åˆ° {zip_path}")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.write(filepath, arcname=base_filename)
        
        zip_size = os.path.getsize(zip_path)
        if zip_size <= max_size:
            logger.info(f"å‹ç¼©åå¤§å° ({zip_size} bytes) åœ¨é™åˆ¶å†…ï¼Œå‘é€å‹ç¼©æ–‡ä»¶ã€‚")
            await context.bot.send_document(chat_id, document=open(zip_path, 'rb'), connect_timeout=60, read_timeout=60,
                                            caption=f"æ–‡ä»¶ '{base_filename}' å› è¿‡å¤§å·²è¢«å‹ç¼©ã€‚")
            os.remove(zip_path)
            return
        
        os.remove(zip_path) # æ¸…ç†æœªåˆ†å·çš„å‹ç¼©æ–‡ä»¶

        # ç­–ç•¥3: åˆ†å·å‹ç¼©å‘é€
        logger.info(f"å‹ç¼©åä»è¿‡å¤§ï¼Œå¼€å§‹åˆ†å·å‹ç¼©ã€‚")
        split_size = max_size - (1024 * 1024) # ç•™å‡º1MBçš„ä½™é‡
        
        with tempfile.TemporaryDirectory() as tmp_dir:
            zip_base_name = os.path.join(tmp_dir, base_filename)
            part_num = 1
            with zipfile.ZipFile(f"{zip_base_name}.zip.001", 'w', zipfile.ZIP_DEFLATED) as zf:
                total_size = 0
                
                # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„å¤§æ–‡ä»¶æ¥è¿›è¡Œåˆ†å·æµ‹è¯•
                # In a real scenario, you'd process the actual large file
                zf.write(filepath, arcname=base_filename)
            
            # è¿™éƒ¨åˆ†éœ€è¦ä¸€ä¸ªæ›´å¤æ‚çš„é€»è¾‘æ¥çœŸå®åœ°åˆ†å‰²ä¸€ä¸ªå¤§æ–‡ä»¶çš„å‹ç¼©æµ
            # `zipfile`åº“ä¸ç›´æ¥æ”¯æŒåˆ†å·å†™å…¥ã€‚éœ€è¦æ‰‹åŠ¨ç®¡ç†æµã€‚
            # ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œç›´æ¥åˆ†å‰²å‹ç¼©å¥½çš„æ–‡ä»¶
            with open(zip_path, 'rb') as f_in:
                 part_num = 1
                 while True:
                    part_filename = f"{zip_path}.{str(part_num).zfill(3)}"
                    with open(part_filename, 'wb') as f_out:
                        chunk = f_in.read(split_size)
                        if not chunk:
                            break
                        f_out.write(chunk)
                    
                    logger.info(f"å‘é€åˆ†å·: {part_filename}")
                    await context.bot.send_document(chat_id, document=open(part_filename, 'rb'),
                                                    caption=f"'{base_filename}' åˆ†å· {part_num}",
                                                    connect_timeout=60, read_timeout=60)
                    os.remove(part_filename)
                    part_num += 1

            if os.path.exists(zip_path):
                 os.remove(zip_path)

            await update.message.reply_text(f"âœ… æ–‡ä»¶å·²åˆ†å·å‹ç¼©å¹¶å‘é€å®Œæ¯•ã€‚è¯·ä¸‹è½½æ‰€æœ‰åˆ†å·åè§£å‹ã€‚")


    except Exception as e:
        logger.error(f"å‘é€æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}", exc_info=True)
        await update.message.reply_text(f"â›”ï¸ å‘é€æ–‡ä»¶æ—¶é‡åˆ°é”™è¯¯: {e}")


# --- åŠ è½½é…ç½® ---
CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
HISTORY = load_json_file(HISTORY_FILE, {})

# --- æƒé™å’Œè£…é¥°å™¨ ---
def is_super_admin(user_id: int) -> bool:
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºè¶…çº§ç®¡ç†å‘˜ï¼ˆç®¡ç†å‘˜åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªï¼‰"""
    return user_id in CONFIG['admins'] and CONFIG['admins'].index(user_id) == 0

def is_admin(user_id: int) -> bool:
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºç®¡ç†å‘˜"""
    return user_id in CONFIG['admins']

def admin_only(func):
    """è£…é¥°å™¨ï¼šé™åˆ¶åªæœ‰ç®¡ç†å‘˜æ‰èƒ½è®¿é—®"""
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨ä¸æ˜¯æˆæƒç®¡ç†å‘˜ã€‚"
            if update.callback_query:
                update.callback_query.answer(message_text, show_alert=True)
            elif update.message:
                update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped

def super_admin_only(func):
    """è£…é¥°å™¨ï¼šé™åˆ¶åªæœ‰è¶…çº§ç®¡ç†å‘˜æ‰èƒ½è®¿é—®"""
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_super_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ­¤ä¸ºè¶…çº§ç®¡ç†å‘˜ä¸“å±åŠŸèƒ½ã€‚"
            if update.callback_query:
                update.callback_query.answer(message_text, show_alert=True)
            elif update.message:
                update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped

# --- å‘½ä»¤å¤„ç†å‡½æ•° ---

@admin_only
async def start_command(update: Update, context: CallbackContext):
    """å¤„ç† /start å‘½ä»¤"""
    user = update.effective_user
    await update.message.reply_html(
        f"ğŸ‘‹ ä½ å¥½, {user.mention_html()}!\n\nè¿™æ˜¯ä¸€ä¸ªFOFAæŸ¥è¯¢æœºå™¨äººã€‚ä½¿ç”¨ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤ã€‚",
    )
    
@admin_only
async def help_command(update: Update, context: CallbackContext):
    """å¤„ç† /help å‘½ä»¤"""
    # ... çœç•¥äº† help å†…å®¹çš„å®šä¹‰ ...
    is_super = is_super_admin(update.effective_user.id)
    
    base_commands = """
*æŸ¥è¯¢åŠŸèƒ½*
/fofa <query> \- æ‰§è¡ŒFOFAæŸ¥è¯¢
/preview <file> \- å¿«é€Ÿé¢„è§ˆæ–‡ä»¶å†…å®¹
/history \- æŸ¥çœ‹æŸ¥è¯¢å†å²
/file <query> \- åœ¨æŸ¥è¯¢å†å²ä¸­æœç´¢å¹¶è·å–æ–‡ä»¶
    """
    
    super_admin_commands = """
*âš™ï¸ è¶…çº§ç®¡ç†å‘˜è®¾ç½®*
/settings \- æ‰“å¼€è®¾ç½®èœå•
/addadmin <user\_id> \- æ·»åŠ ç®¡ç†å‘˜
/deladmin <user\_id> \- åˆ é™¤ç®¡ç†å‘˜
/addapi <name> <email> <key> \- æ·»åŠ FOFA API
/delapi <name> \- åˆ é™¤FOFA API
/setproxy <url> \- è®¾ç½®ä»£ç†
/delproxy <url> \- åˆ é™¤ä»£ç†
/addpreset <name> <query> \- æ·»åŠ é¢„è®¾æŸ¥è¯¢
/delpreset <name> \- åˆ é™¤é¢„è®¾æŸ¥è¯¢
/setuploadapi <url> <token> \- è®¾ç½®ä¸Šä¼ API
/backup \- å¤‡ä»½æ‰€æœ‰JSONé…ç½®æ–‡ä»¶
/selfupdate \- è‡ªæˆ‘æ›´æ–°
    """

    help_text = escape_markdown_v2("å¯ç”¨å‘½ä»¤:\n") + base_commands
    if is_super:
        help_text += super_admin_commands

    await update.message.reply_text(help_text, parse_mode='MarkdownV2')


# --- è®¾ç½®èœå• (è¶…çº§ç®¡ç†å‘˜ä¸“å±) ---
SETTINGS_MENU, ADMIN_SETTINGS_MENU = range(2)

@super_admin_only
async def settings_command(update: Update, context: CallbackContext):
    """æ˜¾ç¤ºè®¾ç½®èœå•"""
    keyboard = [
        [InlineKeyboardButton(f"ç»¼åˆæŸ¥è¯¢æ¨¡å¼: {'âœ…' if CONFIG.get('full_mode') else 'âŒ'}", callback_data='toggle_full_mode')],
        [InlineKeyboardButton(f"å…¬å¼€æ¨¡å¼: {'âœ…' if CONFIG.get('public_mode') else 'âŒ'}", callback_data='toggle_public_mode')],
        [InlineKeyboardButton(f"æ˜¾ç¤ºä¸‹è½½é“¾æ¥: {'âœ…' if CONFIG.get('show_download_links', True) else 'âŒ'}", callback_data='toggle_show_download_links')],
        [InlineKeyboardButton("å…³é—­èœå•", callback_data='close_settings')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text('âš™ï¸ *æœºå™¨äººè®¾ç½®*', reply_markup=reply_markup, parse_mode='Markdown')
    return SETTINGS_MENU

@admin_only
async def settings_menu_handler(update: Update, context: CallbackContext):
    """å¤„ç†æ™®é€šç®¡ç†å‘˜å’Œè¶…çº§ç®¡ç†å‘˜çš„èœå•è®¿é—®"""
    if is_super_admin(update.effective_user.id):
        # å®Œæ•´çš„è®¾ç½®èœå•
        return await settings_command(update, context)
    else:
        # å—é™çš„èœå•ï¼ˆæˆ–æ— èœå•ï¼‰
        await update.message.reply_text(" à¤•à¥‡à¤µà¤² à¤¸à¥à¤ªà¤° à¤à¤¡à¤®à¤¿à¤¨ à¤¹à¥€ à¤¸à¥‡à¤Ÿà¤¿à¤‚à¤—à¥à¤¸ à¤¬à¤¦à¤² à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤")
        return ConversationHandler.END

async def toggle_setting_handler(update: Update, context: CallbackContext):
    """å¤„ç†åˆ‡æ¢é…ç½®é€‰é¡¹"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    if not is_super_admin(user_id):
        await query.answer("â›”ï¸ æƒé™ä¸è¶³ï¼", show_alert=True)
        return SETTINGS_MENU
        
    toggle_map = {
        'toggle_full_mode': 'full_mode',
        'toggle_public_mode': 'public_mode',
        'toggle_show_download_links': 'show_download_links'
    }
    
    setting_key = toggle_map.get(query.data)
    if not setting_key:
        await query.answer("å†…éƒ¨é”™è¯¯", show_alert=True)
        return SETTINGS_MENU

    CONFIG[setting_key] = not CONFIG.get(setting_key, False if setting_key != 'show_download_links' else True)
    save_json_file(CONFIG_FILE, CONFIG)

    # é‡æ–°ç”Ÿæˆé”®ç›˜ä»¥åæ˜ æ–°çŠ¶æ€
    keyboard = [
        [InlineKeyboardButton(f"ç»¼åˆæŸ¥è¯¢æ¨¡å¼: {'âœ…' if CONFIG.get('full_mode') else 'âŒ'}", callback_data='toggle_full_mode')],
        [InlineKeyboardButton(f"å…¬å¼€æ¨¡å¼: {'âœ…' if CONFIG.get('public_mode') else 'âŒ'}", callback_data='toggle_public_mode')],
        [InlineKeyboardButton(f"æ˜¾ç¤ºä¸‹è½½é“¾æ¥: {'âœ…' if CONFIG.get('show_download_links', True) else 'âŒ'}", callback_data='toggle_show_download_links')],
        [InlineKeyboardButton("å…³é—­èœå•", callback_data='close_settings')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await query.edit_message_text(text='âš™ï¸ *æœºå™¨äººè®¾ç½®*', reply_markup=reply_markup, parse_mode='Markdown')
    return SETTINGS_MENU

async def close_settings_handler(update: Update, context: CallbackContext):
    """å…³é—­è®¾ç½®èœå•"""
    query = update.callback_query
    await query.answer()
    await query.edit_message_text(text="è®¾ç½®èœå•å·²å…³é—­ã€‚")
    return ConversationHandler.END
    
async def invalid_settings_option(update: Update, context: CallbackContext):
    """å¤„ç†æ— æ•ˆçš„è®¾ç½®é€‰é¡¹"""
    await update.message.reply_text("æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡è¯•ã€‚")
    return SETTINGS_MENU

# --- é…ç½®æ–‡ä»¶ç®¡ç† (å¤‡ä»½/æ¢å¤) ---
@super_admin_only
async def backup_config_command(update: Update, context: CallbackContext):
    """å¤‡ä»½æ‰€æœ‰.jsonæ–‡ä»¶åˆ°ä¸€ä¸ªzipå‹ç¼©åŒ…ä¸­"""
    chat_id = update.effective_chat.id
    try:
        json_files = glob.glob('*.json')
        if not json_files:
            await update.message.reply_text("æœªæ‰¾åˆ°ä»»ä½• .json æ–‡ä»¶è¿›è¡Œå¤‡ä»½ã€‚")
            return

        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ–‡ä»¶æ¥å­˜å‚¨zip
        with tempfile.NamedTemporaryFile(prefix='backup_', suffix='.zip', delete=False) as tmp_zip_file:
            zip_filename = tmp_zip_file.name

        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zf:
            for file in json_files:
                zf.write(file)
        
        await context.bot.send_document(
            chat_id=chat_id,
            document=open(zip_filename, 'rb'),
            filename=f"bot_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            caption=f"âœ… æˆåŠŸå¤‡ä»½ {len(json_files)} ä¸ªé…ç½®æ–‡ä»¶ã€‚"
        )
        os.remove(zip_filename) # å‘é€ååˆ é™¤ä¸´æ—¶æ–‡ä»¶

    except Exception as e:
        logger.error(f"å¤‡ä»½å¤±è´¥: {e}", exc_info=True)
        await update.message.reply_text(f"â›”ï¸ å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

RECEIVING_CONFIG = range(1)
async def receive_config_file_entry(update: Update, context: CallbackContext):
    if not is_super_admin(update.effective_user.id):
        await update.message.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œæ­¤ä¸ºè¶…çº§ç®¡ç†å‘˜ä¸“å±åŠŸèƒ½ã€‚")
        return ConversationHandler.END
    await update.message.reply_text("è¯·ç›´æ¥å‘é€æ‚¨çš„ `config.json` æˆ–åŒ…å«æ‰€æœ‰é…ç½®çš„ `.zip` å¤‡ä»½æ–‡ä»¶ç»™æˆ‘ã€‚")
    return RECEIVING_CONFIG

async def receive_config_file(update: Update, context: CallbackContext):
    """æ¥æ”¶å¹¶å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„é…ç½®æ–‡ä»¶"""
    # ä¿®å¤äº† global å£°æ˜çš„è¯­æ³•
    global CONFIG
    global HISTORY
    
    document = update.message.document
    if not document:
        await update.message.reply_text("è¯·å‘é€æ–‡ä»¶ã€‚")
        return RECEIVING_CONFIG

    file_extension = os.path.splitext(document.file_name)[1].lower()
    
    try:
        with tempfile.TemporaryDirectory() as tmp_dir:
            file_path = os.path.join(tmp_dir, document.file_name)
            bot_file = await context.bot.get_file(document.file_id)
            await bot_file.download_to_drive(custom_path=file_path)

            if file_extension == '.json':
                # å¤„ç†å•ä¸ªJSONæ–‡ä»¶
                os.replace(file_path, CONFIG_FILE)
                CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
                await update.message.reply_text("âœ… `config.json` å·²æˆåŠŸæ›´æ–°ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ–°é…ç½®ã€‚")

            elif file_extension == '.zip':
                # å¤„ç†ZIPå¤‡ä»½æ–‡ä»¶
                with zipfile.ZipFile(file_path, 'r') as zf:
                    json_files_in_zip = [f for f in zf.namelist() if f.endswith('.json')]
                    if not json_files_in_zip:
                        await update.message.reply_text("â›”ï¸ Zipæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½• .json é…ç½®æ–‡ä»¶ã€‚")
                        return RECEIVING_CONFIG
                    
                    zf.extractall('.') # è§£å‹åˆ°å½“å‰ç›®å½•
                
                # é‡æ–°åŠ è½½é…ç½®
                CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
                HISTORY = load_json_file(HISTORY_FILE, {})

                await update.message.reply_text(
                    f"âœ… å·²ä»zipæ–‡ä»¶ä¸­æˆåŠŸæ¢å¤ {len(json_files_in_zip)} ä¸ªæ–‡ä»¶ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ã€‚"
                )
            else:
                await update.message.reply_text("â›”ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚è¯·å‘é€ `.json` æˆ– `.zip` æ–‡ä»¶ã€‚")
                return RECEIVING_CONFIG

        # è§¦å‘é‡å¯
        asyncio.create_task(context.application.shutdown())
        return ConversationHandler.END

    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®å¤±è´¥: {e}", exc_info=True)
        await update.message.reply_text(f"â›”ï¸ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return ConversationHandler.END

async def cancel_receive_config(update: Update, context: CallbackContext):
    """å–æ¶ˆæ¥æ”¶æ–‡ä»¶"""
    await update.message.reply_text("å·²å–æ¶ˆæ“ä½œã€‚")
    return ConversationHandler.END
    
# å…¶ä»–è¢«çœç•¥çš„å‘½ä»¤ï¼ˆaddadmin, deladmin, ç­‰ï¼‰å°†åœ¨è¿™é‡Œ
# ä¸ºäº†ç®€æ´ï¼Œæˆ‘ä»¬ä»…å®ç°æ ¸å¿ƒé€»è¾‘
# ...
@super_admin_only
async def add_admin_command(update: Update, context: CallbackContext):
    try:
        user_id = int(context.args[0])
        if user_id not in CONFIG['admins']:
            CONFIG['admins'].append(user_id)
            save_json_file(CONFIG_FILE, CONFIG)
            await update.message.reply_text(f"âœ… ç®¡ç†å‘˜ {user_id} æ·»åŠ æˆåŠŸã€‚")
        else:
            await update.message.reply_text(f"â„¹ï¸ ç”¨æˆ· {user_id} å·²ç»æ˜¯ç®¡ç†å‘˜ã€‚")
    except (IndexError, ValueError):
        await update.message.reply_text("ç”¨æ³•: /addadmin <user_id>")

@super_admin_only
async def del_admin_command(update: Update, context: CallbackContext):
    try:
        user_id = int(context.args[0])
        if user_id in CONFIG['admins']:
            # è¶…çº§ç®¡ç†å‘˜ä¸èƒ½è¢«åˆ é™¤
            if CONFIG['admins'].index(user_id) == 0:
                await update.message.reply_text("â›”ï¸ ä¸èƒ½åˆ é™¤è¶…çº§ç®¡ç†å‘˜ã€‚")
                return
            CONFIG['admins'].remove(user_id)
            save_json_file(CONFIG_FILE, CONFIG)
            await update.message.reply_text(f"âœ… ç®¡ç†å‘˜ {user_id} åˆ é™¤æˆåŠŸã€‚")
        else:
            await update.message.reply_text(f"â„¹ï¸ ç”¨æˆ· {user_id} ä¸æ˜¯ç®¡ç†å‘˜ã€‚")
    except (IndexError, ValueError):
        await update.message.reply_text("ç”¨æ³•: /deladmin <user_id>")

def fetch_fofa_stats(key, query, proxy_session=None):
    params = {'key': key, 'q': query, 'fields': FOFA_STATS_FIELDS}
    return _make_api_request(FOFA_STATS_URL, params, proxy_session=proxy_session)

def fetch_fofa_host_info(key, host, detail=False, proxy_session=None):
    url = FOFA_HOST_BASE_URL + host
    params = {'key': key, 'detail': str(detail).lower()}
    return _make_api_request(url, params, use_b64=False, proxy_session=proxy_session)
def fetch_fofa_next_data(key, query, next_id=None, page_size=10000, fields="host", proxy_session=None):
    params = {'key': key, 'q': query, 'size': page_size, 'fields': fields, 'full': CONFIG.get("full_mode", False)}
    # FIX: Ensure 'next' parameter is always present, and empty on the first call, to comply with API spec.
    params['next'] = next_id if next_id is not None else ""
    return _make_api_request(FOFA_NEXT_URL, params, proxy_session=proxy_session)

# --- æ™ºèƒ½ä¸‹è½½æ ¸å¿ƒå·¥å…· ---
def iter_fofa_traceback(key, query, limit=None, proxy_session=None, page_size=10000):
    """
    é€šè¿‡ before/after æ—¶é—´å›æº¯æœºåˆ¶è¿­ä»£è·å–æ•°æ®çš„ç”Ÿæˆå™¨ã€‚
    Yields: ç»“æœåˆ—è¡¨
    """
    current_query = query
    last_page_date = None
    collected_count = 0
    
    # ç®€å•çš„å“ˆå¸Œå»é‡ï¼ˆç”¨äºå¤„ç†åŒä¸€å¤©çš„åˆ†é¡µé‡å ï¼‰
    page_hashes = set() 
    
    while True:
        # è·å–ç¬¬ä¸€é¡µ
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è¯·æ±‚ lastupdatetime ä»¥ä¾¿ç¡®å®šä¸‹ä¸€é¡µçš„ before æ—¶é—´é”šç‚¹
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œå¦‚æœæ²¡æœ‰ VIP æƒé™ï¼Œè¿™ä¸ª fields è¯·æ±‚å¯èƒ½ä¼šè¢«å¿½ç•¥æˆ–è€…éœ€è¦å¤–éƒ¨ç¡®ä¿ Key æƒé™
        # è¿™é‡Œå‡è®¾è°ƒç”¨æ­¤å‡½æ•°æ—¶å·²ä½¿ç”¨äº†å…·å¤‡æƒé™çš„ Key
        fields = "host,lastupdatetime"
        
        # ä½¿ç”¨ execute_query_with_fallback çš„ç­‰ä»·å•æ¬¡è°ƒç”¨ï¼Œæˆ–è€…ç›´æ¥è°ƒ fetchã€‚
        # è¿™é‡Œæ˜¯è¿­ä»£å™¨å†…éƒ¨ï¼Œå‡å®š key æ˜¯ç¡®å®šçš„ã€‚
        # å¦‚æœ Key ç­‰çº§ < 1 (æ— æ³•æŸ¥è¯¢ lastupdatetime)ï¼Œåˆ™åªèƒ½æŸ¥æ™®é€šç¿»é¡µï¼Œè¿™ä¼šå¯¼è‡´å¤§é‡æ•°æ®ä¸‹çš„æ­»å¾ªç¯ï¼Œ
        # æ‰€ä»¥å¤–éƒ¨å¿…é¡»ç¡®ä¿ key level >= 1
        
        data, error = fetch_fofa_data(key, current_query, page=1, page_size=page_size, fields=fields, proxy_session=proxy_session)
        
        if error or not data or not data.get('results'):
            break

        results = data.get('results', [])
        if not results:
            break

        # Yield current batch
        # æˆ‘ä»¬è¿”å›å®Œæ•´ç»“æœä»¥ä¾¿å¤–éƒ¨å¤„ç†
        yield results
        collected_count += len(results)
        if limit and collected_count >= limit:
            break

        # åˆ†ææœ€åä¸€æ¡çš„æ—¶é—´ï¼Œè®¾ç½®æ–°çš„ Time Anchor
        # FOFA ç»“æœæ˜¯å€’åºçš„ï¼Œæœ€åä¸€æ¡æ˜¯æœ€æ—§çš„
        # å–æœ€åä¸€æ¡çš„æ—¶é—´ï¼Œä½œä¸ºä¸‹ä¸€è½®çš„ before
        valid_anchor_found = False
        
        # å€’åºå¯»æ‰¾æœ‰æ•ˆæ—¶é—´æˆ³
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2: continue
            
            # æ ¼å¼å¯èƒ½æ˜¯ "2023-01-01 12:00:00"
            ts_str = results[i][-1] # lastupdatetime
            try:
                current_date_obj = datetime.strptime(ts_str.split(' ')[0], '%Y-%m-%d').date()
                
                # é˜²æ­¢æ­»å¾ªç¯ï¼šå¦‚æœè¿™é¡µæ‰¾åˆ°çš„æ—¥æœŸ >= ä¸Šä¸€é¡µæ‰¾åˆ°çš„é”šç‚¹æ—¥æœŸï¼Œè¯´æ˜åœ¨è¿™ä¸€å¤©å†…å¡ä½äº†
                # æˆ‘ä»¬éœ€è¦å¼ºåˆ¶å°†æ—¥æœŸ -1 å¤©æ¥è·³è¿‡è¿™ä¸€å¤©ï¼ˆä¼šæœ‰æ•°æ®æŸå¤±ï¼Œä½†å¥½è¿‡æ­»å¾ªç¯ï¼‰
                # æˆ–è€…ï¼ŒFOFA api æ”¯æŒ page ç¿»é¡µï¼Œå¦‚æœæ˜¯åœ¨åŒä¸€å¤©ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ç¿» page 2?
                # ç®€åŒ–èµ·è§ï¼šTime Slicing ç­–ç•¥æ˜¯â€œå¤©â€çº§çš„ã€‚å¦‚æœä¸€å¤© > 10000 æ¡ï¼Œè¿™é‡Œçš„é€»è¾‘ä¼šè·³è¿‡å½“å¤©å‰©ä½™æ•°æ®ã€‚
                # ä½†æ ¹æ® Smart Slicing å‡è®¾ï¼Œå›½å®¶è¢«å‰¥ç¦»åï¼Œå•æ—¥å•å›½æ•°æ®å¾ˆéš¾ > 10000ã€‚
                
                next_page_date_obj = current_date_obj
                
                if last_page_date and current_date_obj >= last_page_date:
                    # å¦‚æœæ—¶é—´æ²¡æœ‰å‰æ¨ï¼Œå¼ºåˆ¶ -1 å¤©
                    next_page_date_obj -= timedelta(days=1)
                
                last_page_date = next_page_date_obj
                
                # æ›´æ–°æŸ¥è¯¢ï¼šè¿½åŠ  before å‚æ•°
                # æ³¨æ„å¤„ç† query ä¸­ç°æœ‰çš„æ‹¬å·
                current_query = f'({query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'
                valid_anchor_found = True
                break
            except (ValueError, TypeError, IndexError):
                continue
        
        if not valid_anchor_found:
            break

def check_and_classify_keys():
    logger.info("--- å¼€å§‹æ£€æŸ¥å¹¶åˆ†ç±»API Keys ---")
    global KEY_LEVELS
    KEY_LEVELS.clear()
    for key in CONFIG.get('apis', []):
        data, error = verify_fofa_api(key)
        if error:
            logger.warning(f"Key '...{key[-4:]}' æ— æ•ˆ: {error}")
            KEY_LEVELS[key] = -1
            continue
        is_vip = data.get('isvip', False)
        api_level = data.get('vip_level', 0)
        level = 0
        if not is_vip:
            level = 0
        else:
            if api_level == 2: level = 1
            elif api_level == 3: level = 2
            elif api_level >= 4: level = 3
            else: level = 1 
        KEY_LEVELS[key] = level
        level_name = {0: "å…è´¹ä¼šå‘˜", 1: "ä¸ªäººä¼šå‘˜", 2: "å•†ä¸šä¼šå‘˜", 3: "ä¼ä¸šä¼šå‘˜"}.get(level, "æœªçŸ¥ç­‰çº§")
        logger.info(f"Key '...{key[-4:]}' ({data.get('username', 'N/A')}) - ç­‰çº§: {level} ({level_name})")
    logger.info("--- API Keys åˆ†ç±»å®Œæˆ ---")

def get_fields_by_level(level):
    if level >= 3: return ENTERPRISE_FIELDS
    if level == 2: return BUSINESS_FIELDS
    if level == 1: return PERSONAL_FIELDS
    return FREE_FIELDS

def execute_query_with_fallback(query_func, preferred_key_index=None, proxy_session=None, min_level=0):
    if not CONFIG['apis']: return None, None, None, None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    
    keys_to_try = [k for k in CONFIG['apis'] if KEY_LEVELS.get(k, -1) >= min_level]
    
    if not keys_to_try:
        if min_level > 0:
            return None, None, None, None, None, f"æ²¡æœ‰æ‰¾åˆ°ç­‰çº§ä¸ä½äºâ€œä¸ªäººä¼šå‘˜â€çš„æœ‰æ•ˆAPI Keyä»¥æ‰§è¡Œæ­¤æ“ä½œã€‚"
        return None, None, None, None, None, "æ‰€æœ‰é…ç½®çš„API Keyéƒ½æ— æ•ˆã€‚"
    
    start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(CONFIG['apis']):
        preferred_key = CONFIG['apis'][preferred_key_index - 1]
        if preferred_key in keys_to_try:
            start_index = keys_to_try.index(preferred_key)

    # v10.9.4 FIX: å¦‚æœæœªé”å®šä»£ç†ä¼šè¯ï¼Œåˆ™åœ¨æ­¤å›é€€åºåˆ—çš„æŒç»­æ—¶é—´å†…é€‰æ‹©ä¸€ä¸ªã€‚
    current_proxy_session_str = proxy_session
    if current_proxy_session_str is None:
        proxies_list = CONFIG.get("proxies", [])
        if proxies_list:
            current_proxy_session_str = random.choice(proxies_list)
        else:
            current_proxy_session_str = CONFIG.get("proxy")

    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try)
        key = keys_to_try[idx]
        key_num = CONFIG['apis'].index(key) + 1
        key_level = KEY_LEVELS.get(key, 0)
        
        # v10.9.4 FIX: å°†keyã€key_levelå’Œä¸€è‡´çš„proxy_sessionä¼ é€’ç»™æŸ¥è¯¢å‡½æ•°ã€‚
        data, error = query_func(key, key_level, current_proxy_session_str)
        
        if not error:
            # è¿”å›æˆåŠŸä½¿ç”¨çš„ä»£ç†ã€‚
            return data, key, key_num, key_level, current_proxy_session_str, None
        
        error_str = str(error)
        if "[820031]" in error_str:
            logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³...");
            continue
        if "[45022]" in error_str:
            logger.warning(f"Key [#{key_num}] ä»Šæ—¥è¯·æ±‚æ¬¡æ•°å·²è¾¾ä¸Šé™...");
            continue

        # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œå¿«é€Ÿå¤±è´¥å¹¶è¿”å›é—®é¢˜keyçš„ä¿¡æ¯
        return None, key, key_num, key_level, current_proxy_session_str, error
        
    return None, None, None, None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ (å¯èƒ½Fç‚¹å‡ä¸è¶³)ã€‚"

# --- å¼‚æ­¥æ‰«æé€»è¾‘ ---
async def async_check_port(host, port, timeout):
    try:
        fut = asyncio.open_connection(host, port)
        _, writer = await asyncio.wait_for(fut, timeout=timeout)
        writer.close(); await writer.wait_closed()
        return f"{host}:{port}"
    except (asyncio.TimeoutError, ConnectionRefusedError, OSError, socket.gaierror): return None
    except Exception: return None

async def async_scanner_orchestrator(scan_targets, concurrency, timeout, progress_callback=None):
    semaphore = asyncio.Semaphore(concurrency)
    total_tasks = len(scan_targets)
    completed_tasks = 0
    
    async def worker(host, port):
        nonlocal completed_tasks
        async with semaphore:
            result = await async_check_port(host, port, timeout)
            completed_tasks += 1
            if progress_callback:
                await progress_callback(completed_tasks, total_tasks)
            return result

    tasks = [worker(host, port) for host, port in scan_targets]
    results = await asyncio.gather(*tasks)
    return [res for res in results if res is not None]

def run_async_scan_job(context: CallbackContext):
    job_context = context.job.context
    chat_id, msg, original_query, mode = job_context['chat_id'], job_context['msg'], job_context['original_query'], job_context['mode']
    concurrency, timeout = job_context['concurrency'], job_context['timeout']
    
    cached_item = find_cached_query(original_query)
    if not cached_item:
        try: msg.edit_text("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶çš„æœ¬åœ°ç¼“å­˜è®°å½•ã€‚")
        except (BadRequest, RetryAfter, TimedOut): pass
        return

    try: msg.edit_text("1/3: æ­£åœ¨è§£æå’ŒåŠ è½½ç›®æ ‡...")
    except (BadRequest, RetryAfter, TimedOut): pass
    
    try:
        with open(cached_item['cache']['file_path'], 'r', encoding='utf-8') as f:
            raw_targets = [line.strip() for line in f if line.strip()]
    except Exception as e:
        try: msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
        except (BadRequest, RetryAfter, TimedOut): pass
        return
        
    scan_targets = []
    scan_type_text = ""
    if mode == 'tcping':
        scan_type_text = "TCPå­˜æ´»æ‰«æ"
        for t in raw_targets:
            try:
                # Handle URLs with schema
                if t.startswith('http://') or t.startswith('https://'):
                    parsed_url = urlparse(t)
                    hostname = parsed_url.hostname
                    port = parsed_url.port
                    if port is None:
                        port = 443 if parsed_url.scheme == 'https' else 80
                    if hostname:
                        # Strip brackets from IPv6 hostnames for socket connection
                        hostname = hostname.strip("[]")
                        scan_targets.append((hostname, port))
                    continue
                
                # Handle IPv6 in brackets like [ipv6]:port
                match = re.match(r'\[([a-fA-F0-9:]+)\]:(\d+)', t)
                if match:
                    scan_targets.append((match.group(1), int(match.group(2))))
                    continue

                # Handle host:port (IPv4 or domain)
                host, port_str = t.rsplit(':', 1)
                if host and port_str:
                    scan_targets.append((host, int(port_str)))
            except (ValueError, IndexError):
                logger.warning(f"æ— æ³•è§£ææ‰«æç›®æ ‡: {t}, å·²è·³è¿‡ã€‚")
                continue

    elif mode == 'subnet':
        scan_type_text = "å­ç½‘æ‰«æ"
        subnets_to_ports = {}
        for line in raw_targets:
            try:
                ip_str, port_str = line.strip().split(':'); port = int(port_str)
                # Basic check for IPv4 before splitting
                if '.' in ip_str and len(ip_str.split('.')) == 4:
                    subnet = ".".join(ip_str.split('.')[:3])
                    if subnet not in subnets_to_ports: subnets_to_ports[subnet] = set()
                    subnets_to_ports[subnet].add(port)
                else:
                    logger.warning(f"å­ç½‘æ‰«æè·³è¿‡éIPv4ç›®æ ‡: {line}")
            except ValueError:
                logger.warning(f"å­ç½‘æ‰«ææ— æ³•è§£æè¡Œ: {line}")
                continue
        for subnet, ports in subnets_to_ports.items():
            for i in range(1, 255):
                for port in ports:
                    scan_targets.append((f"{subnet}.{i}", port))

    if not scan_targets:
        try: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªèƒ½ä»æ–‡ä»¶ä¸­è§£æå‡ºä»»ä½•æœ‰æ•ˆçš„ç›®æ ‡ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æ ¼å¼ã€‚")
        except (BadRequest, RetryAfter, TimedOut): pass
        return
        
    async def main_scan_logic():
        last_update_time = 0
        
        async def progress_callback(completed, total):
            nonlocal last_update_time
            current_time = time.time()
            if total > 0 and current_time - last_update_time > 2:
                percentage = (completed / total) * 100
                progress_bar = create_progress_bar(percentage)
                try:
                    msg.edit_text(
                        f"2/3: æ­£åœ¨è¿›è¡Œå¼‚æ­¥{scan_type_text}...\n"
                        f"{progress_bar} ({completed}/{total})"
                    )
                    last_update_time = current_time
                except (BadRequest, RetryAfter, TimedOut):
                    pass # Ignore if editing fails, continue scanning

        initial_message = f"2/3: å·²åŠ è½½ {len(scan_targets)} ä¸ªæœ‰æ•ˆç›®æ ‡ï¼Œå¼€å§‹å¼‚æ­¥{scan_type_text} (å¹¶å‘: {concurrency}, è¶…æ—¶: {timeout}s)..."
        try:
            msg.edit_text(initial_message)
        except (BadRequest, RetryAfter, TimedOut):
            pass

        return await async_scanner_orchestrator(scan_targets, concurrency, timeout, progress_callback)

    live_results = asyncio.run(main_scan_logic())
    
    if not live_results:
        try: msg.edit_text("ğŸ¤·â€â™€ï¸ æ‰«æå®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•å­˜æ´»çš„ç›®æ ‡ã€‚")
        except (BadRequest, RetryAfter, TimedOut): pass
        return

    try: msg.edit_text("3/3: æ­£åœ¨æ‰“åŒ…å¹¶å‘é€æ–°ç»“æœ...")
    except (BadRequest, RetryAfter, TimedOut): pass
    
    output_filename = generate_filename_from_query(original_query, prefix=f"{mode}_scan")
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(live_results))))
    
    final_caption = f"âœ… *å¼‚æ­¥{escape_markdown_v2(scan_type_text)}å®Œæˆ\!*\n\nå…±å‘ç° *{len(live_results)}* ä¸ªå­˜æ´»ç›®æ ‡\\."
    send_file_safely(context, chat_id, output_filename, caption=final_caption, parse_mode=ParseMode.MARKDOWN_V2)
    upload_and_send_links(context, chat_id, output_filename)
    os.remove(output_filename)
    try: msg.delete()
    except (BadRequest, RetryAfter, TimedOut): pass

# --- æ‰«ææµç¨‹å…¥å£ ---
def offer_post_download_actions(context: CallbackContext, chat_id, query_text):
    query_hash = hashlib.md5(query_text.encode()).hexdigest()
    SCAN_TASKS[query_hash] = query_text
    while len(SCAN_TASKS) > MAX_SCAN_TASKS:
        SCAN_TASKS.pop(next(iter(SCAN_TASKS)))
    save_scan_tasks()

    keyboard = [[
        InlineKeyboardButton("âš¡ï¸ å¼‚æ­¥TCPå­˜æ´»æ‰«æ", callback_data=f'start_scan_tcping_{query_hash}'),
        InlineKeyboardButton("ğŸŒ å¼‚æ­¥å­ç½‘æ‰«æ(/24)", callback_data=f'start_scan_subnet_{query_hash}')
    ]]
    context.bot.send_message(chat_id, "ä¸‹è½½å®Œæˆï¼Œéœ€è¦å¯¹ç»“æœè¿›è¡ŒäºŒæ¬¡æ‰«æå—ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard))
def start_scan_callback(update: Update, context: CallbackContext) -> int:
    query = update.callback_query; query.answer()
    # v10.9.1 FIX: Correctly parse callback data to get mode and query_hash
    try:
        _, _, mode, query_hash = query.data.split('_', 3)
    except ValueError:
        logger.error(f"æ— æ³•ä»å›è°ƒæ•°æ®è§£ææ‰«æä»»åŠ¡: {query.data}")
        query.message.edit_text("âŒ å†…éƒ¨é”™è¯¯ï¼šæ— æ³•è§£ææ‰«æä»»åŠ¡ã€‚")
        return ConversationHandler.END

    original_query = SCAN_TASKS.get(query_hash)
    if not original_query:
        query.message.edit_text("âŒ æ‰«æä»»åŠ¡å·²è¿‡æœŸæˆ–æœºå™¨äººåˆšåˆšé‡å¯ã€‚è¯·é‡æ–°å‘èµ·æŸ¥è¯¢ä»¥å¯ç”¨æ‰«æã€‚")
        return ConversationHandler.END

    context.user_data['scan_original_query'] = original_query
    context.user_data['scan_mode'] = mode
    query.message.edit_text("è¯·è¾“å…¥æ‰«æå¹¶å‘æ•° (å»ºè®® 100-1000):")
    return SCAN_STATE_GET_CONCURRENCY
def get_concurrency_callback(update: Update, context: CallbackContext) -> int:
    try:
        concurrency = int(update.message.text)
        if not 1 <= concurrency <= 5000: raise ValueError
        context.user_data['scan_concurrency'] = concurrency
        update.message.reply_text("è¯·è¾“å…¥è¿æ¥è¶…æ—¶æ—¶é—´ (ç§’, å»ºè®® 1-3):")
        return SCAN_STATE_GET_TIMEOUT
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1-5000 ä¹‹é—´çš„æ•´æ•°ã€‚")
        return SCAN_STATE_GET_CONCURRENCY
def get_timeout_callback(update: Update, context: CallbackContext) -> int:
    try:
        timeout = float(update.message.text)
        if not 0.1 <= timeout <= 10: raise ValueError
        msg = update.message.reply_text("âœ… å‚æ•°è®¾ç½®å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°ã€‚")
        job_context = {
            'chat_id': update.effective_chat.id, 'msg': msg,
            'original_query': context.user_data['scan_original_query'],
            'mode': context.user_data['scan_mode'],
            'concurrency': context.user_data['scan_concurrency'],
            'timeout': timeout
        }
        context.job_queue.run_once(run_async_scan_job, 1, context=job_context, name=f"scan_{update.effective_chat.id}")
        context.user_data.clear()
        return ConversationHandler.END
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 0.1-10 ä¹‹é—´çš„æ•°å­—ã€‚")
        return SCAN_STATE_GET_TIMEOUT

# --- åå°ä¸‹è½½ä»»åŠ¡ ---
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']; job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)
def run_full_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = generate_filename_from_query(query_text); unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter, TimedOut): pass
        guest_key = job_data.get('guest_key')
        if guest_key:
            data, error = fetch_fofa_data(guest_key, query_text, page, 10000, "host")
        else:
            data, _, _, _, _, error = execute_query_with_fallback(
                lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page, 10000, "host", proxy_session=proxy_session)
            )
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', []);
        if not results: break
        unique_results.update(res for res in results if ':' in res)
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data); offer_post_download_actions(context, chat_id, query_text)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)

def run_sharded_download_job(context: CallbackContext):
    """
    æ™ºèƒ½åˆ†ç‰‡ä¸‹è½½ä»»åŠ¡ï¼šæŒ‰å›½å®¶ä»£ç å°†æŸ¥è¯¢æ‹†åˆ†ï¼Œç»•è¿‡å•æ¬¡æŸ¥è¯¢10000æ¡çš„é™åˆ¶ã€‚
    """
    job_data = context.job.context
    bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']
    
    output_filename = generate_filename_from_query(base_query, prefix="sharded")
    unique_results = set()
    stop_flag = f'stop_job_{chat_id}'
    
    msg = bot.send_message(chat_id, f"â³ *å¯åŠ¨æ™ºèƒ½åˆ†ç‰‡ä¸‹è½½*\nç›®æ ‡ï¼šå°†æŸ¥è¯¢æŒ‰ {len(ALL_COUNTRY_CODES)} ä¸ªå›½å®¶åŒºåŸŸæ‹†åˆ†...\næ³¨æ„ï¼šæ­¤æ¨¡å¼å°†æ¶ˆè€—è¾ƒå¤šçš„ API è¯·æ±‚æ¬¡æ•°ã€‚", parse_mode=ParseMode.MARKDOWN_V2)
    
    start_time = time.time()
    last_ui_update_time = 0
    total_codes = len(ALL_COUNTRY_CODES)
    
    # éå†æ‰€æœ‰å›½å®¶
    for i, country_code in enumerate(ALL_COUNTRY_CODES):
        if context.bot_data.get(stop_flag):
            try: msg.edit_text("ğŸ›‘ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢ã€‚")
            except (BadRequest, RetryAfter, TimedOut): pass
            break
            
        current_time = time.time()
        # æ›´æ–°è¿›åº¦UI (æ¯2ç§’æœ€å¤šæ›´æ–°ä¸€æ¬¡)
        if current_time - last_ui_update_time > 2 or i == 0:
            elapsed = current_time - start_time
            speed = len(unique_results) / elapsed if elapsed > 0 else 0
            progress_bar = create_progress_bar((i / total_codes) * 100)
            try:
                msg.edit_text(
                    f"ğŸŒ *æ­£åœ¨åˆ†ç‰‡æ‰«æ...* `{country_code}`\n"
                    f"{escape_markdown_v2(progress_bar)} {i}/{total_codes}\n"
                    f"å·²æ”¶é›†æ•°æ®: *{len(unique_results)}* æ¡\n"
                    f"å½“å‰å¹³å‡é€Ÿåº¦: *{int(speed)}* æ¡/ç§’",
                    parse_mode=ParseMode.MARKDOWN_V2
                )
                last_ui_update_time = current_time
            except (BadRequest, RetryAfter, TimedOut):
                pass

        # æ„é€ åˆ†ç‰‡æŸ¥è¯¢
        sharded_query = f'({base_query}) && country="{country_code}"'
        
        # å†…éƒ¨æŸ¥è¯¢å‡½æ•°
        def query_logic(key, key_level, proxy_session):
            # ä¸ºäº†èŠ‚çœæµé‡å’Œé€Ÿåº¦ï¼Œé»˜è®¤åªè¯·æ±‚ç¬¬ä¸€é¡µ (max 10000 per country is usually enough for most cases)
            return fetch_fofa_data(key, sharded_query, page=1, page_size=10000, fields="host", proxy_session=proxy_session)

        # å°è¯•æŸ¥è¯¢
        guest_key = job_data.get('guest_key')
        if guest_key:
            data, error = fetch_fofa_data(guest_key, sharded_query, page=1, page_size=10000, fields="host")
        else:
            data, _, _, _, _, error = execute_query_with_fallback(query_logic)
        
        # å¤„ç†ç»“æœ
        if not error and data and data.get('results'):
            new_data = data['results']
            # å¤„ç†ç®€å•å­—ç¬¦ä¸²ç»“æœæˆ–åˆ—è¡¨ç»“æœ
            extracted_hosts = []
            if new_data and isinstance(new_data[0], list):
                 extracted_hosts = [r[0] for r in new_data if r and r[0] and ':' in r[0]]
            else:
                 extracted_hosts = [r for r in new_data if isinstance(r, str) and ':' in r]
            
            unique_results.update(extracted_hosts)
            
            # (å¯é€‰ä¼˜åŒ–) å¦‚æœå•ä¸ªå›½å®¶ç»“æœä¹Ÿæ˜¯æ»¡çš„ 10000ï¼Œç†æƒ³æƒ…å†µåº”è¯¥å†å¯¹è¯¥å›½å®¶æŒ‰ region åˆ†ç‰‡
            # ä½†è¿™é‡Œä¸ºäº†é¿å…æ— é™é€’å½’ï¼Œæš‚æ—¶æ¥å—å•ä¸ªåˆ†ç‰‡ 10000 çš„ä¸Šé™ã€‚å¯¹äºç»å¤§å¤šæ•°å›½å®¶å·²è¶³å¤Ÿã€‚

    # å¾ªç¯ç»“æŸåçš„æ”¶å°¾
    context.bot_data.pop(stop_flag, None)
    
    if unique_results:
        final_count = len(unique_results)
        msg.edit_text(f"âœ… åˆ†ç‰‡æ‰«æå®Œæˆ\!\næ€»è®¡å‘ç° *{final_count}* æ¡å”¯ä¸€æ•°æ®ã€‚\næ­£åœ¨ç”Ÿæˆå¹¶å‘é€æ–‡ä»¶\.\.\.", parse_mode=ParseMode.MARKDOWN_V2)
        
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write("\n".join(sorted(list(unique_results))))
            
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        
        cache_data = {'file_path': cache_path, 'result_count': final_count}
        add_or_update_query(base_query, cache_data)
        offer_post_download_actions(context, chat_id, base_query)
    else:
        msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†åœ¨ä»»ä½•å›½å®¶åˆ†ç‰‡ä¸­éƒ½æœªæ‰¾åˆ°æ•°æ®ã€‚")

def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; limit = job_data.get('limit')
    output_filename = generate_filename_from_query(base_query); unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = set(), 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    guest_key = job_data.get('guest_key')
    
    # v10.9.4 FIX: ä¸ºæ•´ä¸ªè¿½æº¯è¿‡ç¨‹é”å®šä¸€ä¸ªä»£ç†ä¼šè¯
    locked_proxy_session = None

    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break

        fields_were_extended = False
        if guest_key:
            # Guest keys are assumed to be low-level, don't request lastupdatetime
            data, error = fetch_fofa_data(guest_key, current_query, 1, 10000, fields="host")
        else:
            def query_logic(key, key_level, proxy_session):
                nonlocal fields_were_extended
                # Personal members and above can search this field.
                if key_level >= 1:
                    fields_were_extended = True
                    return fetch_fofa_data(key, current_query, 1, 10000, fields="host,lastupdatetime", proxy_session=proxy_session)
                else:
                    fields_were_extended = False
                    return fetch_fofa_data(key, current_query, 1, 10000, fields="host", proxy_session=proxy_session)
            
            # ä»…åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶é€‰æ‹©å¹¶é”å®šä»£ç†
            if locked_proxy_session is None:
                data, _, _, _, locked_proxy_session, error = execute_query_with_fallback(query_logic)
            else:
                data, _, _, _, _, error = execute_query_with_fallback(query_logic, proxy_session=locked_proxy_session)

        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break

        if fields_were_extended:
            newly_added = [r[0] for r in results if r and r[0] and ':' in r[0]]
        else:
            newly_added = [r for r in results if r and ':' in r]
        
        original_count = len(unique_results)
        unique_results.update(newly_added)
        newly_added_count = len(unique_results) - original_count

        if limit and len(unique_results) >= limit: unique_results = set(list(unique_results)[:limit]); termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter, TimedOut): pass
            last_update_time = current_time

        if not fields_were_extended:
             termination_reason = "\n\nâš ï¸ å½“å‰Keyç­‰çº§ä¸æ”¯æŒæ—¶é—´è¿½æº¯ï¼Œå·²è·å–ç¬¬ä¸€é¡µç»“æœã€‚"
             break
        
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        try:
            msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        except (BadRequest, RetryAfter, TimedOut): pass
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data); offer_post_download_actions(context, chat_id, base_query)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)
def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    try: msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜...")
    except (BadRequest, RetryAfter, TimedOut): pass
    cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜é¡¹ã€‚"); return
    old_file_path = cached_item['cache']['file_path']; old_results = set()
    try:
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip() and ':' in line)
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    try: msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹...")
    except (BadRequest, RetryAfter, TimedOut): pass
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_data(key, base_query, fields="lastupdatetime", proxy_session=proxy_session)
    )
    if error or not data.get('results'): msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); return
    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]; cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    try: msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®...")
    except (BadRequest, RetryAfter, TimedOut): pass
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_data(key, incremental_query, page_size=1, proxy_session=proxy_session)
    )
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); return
    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); return
    new_results, stop_flag = set(), f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag):
            try: msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚")
            except (BadRequest, RetryAfter, TimedOut): pass
            return
        try: msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        except (BadRequest, RetryAfter, TimedOut): pass
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, incremental_query, page=page, page_size=10000, proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); return
        if data.get('results'): new_results.update(res for res in data.get('results', []) if ':' in res)
    try: msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)")
    except (BadRequest, RetryAfter, TimedOut): pass
    combined_results = sorted(list(new_results.union(old_results)))
    with open(old_file_path, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    try: msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    except (BadRequest, RetryAfter, TimedOut): pass
    send_file_safely(context, chat_id, old_file_path)
    upload_and_send_links(context, chat_id, old_file_path)
    cache_data = {'file_path': old_file_path, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    msg.delete(); bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼"); offer_post_download_actions(context, chat_id, base_query)
def run_batch_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size, fields = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size'], job_data['fields']
    output_filename = generate_filename_from_query(query_text, prefix="batch_export", ext=".csv"); results_list, stop_flag = [], f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡ºä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(results_list)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter, TimedOut): pass
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page, 10000, fields, proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        page_results = data.get('results', [])
        if not page_results: break
        results_list.extend(page_results)
    if results_list:
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results_list)} æ¡ã€‚æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(results_list)
            send_file_safely(context, chat_id, output_filename, caption=f"âœ… è‡ªå®šä¹‰å¯¼å‡ºå®Œæˆ\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`", parse_mode=ParseMode.MARKDOWN_V2)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch command: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_batch_traceback_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query, fields, limit = context.bot, job_data['chat_id'], job_data['query'], job_data['fields'], job_data.get('limit')
    output_filename = generate_filename_from_query(base_query, prefix="batch_traceback", ext=".csv")
    unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = [], 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query; seen_hashes = set()
    
    # v10.9.4 FIX: ä¸ºæ•´ä¸ªè¿½æº¯è¿‡ç¨‹é”å®šä¸€ä¸ªä»£ç†ä¼šè¯
    locked_proxy_session = None

    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        
        fields_were_extended = False
        def query_logic(key, key_level, proxy_session):
            nonlocal fields_were_extended
            if key_level >= 1:
                fields_were_extended = True
                return fetch_fofa_data(key, current_query, 1, 10000, fields=fields + ",lastupdatetime", proxy_session=proxy_session)
            else:
                fields_were_extended = False
                return fetch_fofa_data(key, current_query, 1, 10000, fields=fields, proxy_session=proxy_session)

        # ä»…åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶é€‰æ‹©å¹¶é”å®šä»£ç†
        if locked_proxy_session is None:
            data, _, _, _, locked_proxy_session, error = execute_query_with_fallback(query_logic)
        else:
            data, _, _, _, _, error = execute_query_with_fallback(query_logic, proxy_session=locked_proxy_session)

        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break

        newly_added_count = 0
        for r in results:
            r_hash = hashlib.md5(str(r).encode()).hexdigest()
            if r_hash not in seen_hashes:
                seen_hashes.add(r_hash)
                unique_results.append(r[:-1] if fields_were_extended else r)
                newly_added_count += 1
        if limit and len(unique_results) >= limit: unique_results = unique_results[:limit]; termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter, TimedOut): pass
            last_update_time = current_time

        if not fields_were_extended:
             termination_reason = "\n\nâš ï¸ å½“å‰Keyç­‰çº§ä¸æ”¯æŒæ—¶é—´è¿½æº¯ï¼Œå·²è·å–ç¬¬ä¸€é¡µç»“æœã€‚"
             break
        
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][-1]: continue
            try:
                timestamp_str = results[i][-1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        msg.edit_text(f"âœ… è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨ç”ŸæˆCSV...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(unique_results)
            send_file_safely(context, chat_id, output_filename)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch traceback: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

# --- ç›‘æ§ç³»ç»Ÿ (Data Reservoir + Radar Mode) ---
def monitor_command(update: Update, context: CallbackContext):
    args = context.args
    if not args:
        help_txt = (
            "ğŸ“¡ *ç›‘æ§é›·è¾¾æŒ‡ä»¤æ‰‹å†Œ*\n\n"
            "`/monitor add <query>` \\- æ·»åŠ æ–°çš„ç›‘æ§ä»»åŠ¡\n"
            "`/monitor list` \\- æŸ¥çœ‹å½“å‰è¿è¡Œçš„ä»»åŠ¡\n"
            "`/monitor get <id>` \\- æ‰“åŒ…æå–ä»»åŠ¡æ•°æ®\n"
            "`/monitor del <id>` \\- åˆ é™¤ç›‘æ§ä»»åŠ¡\n\n"
            "_ç›‘æ§ä»»åŠ¡ä¼šå°†æ–°æ•°æ®è‡ªåŠ¨æ²‰æ·€åˆ°æœ¬åœ°æ•°æ®åº“ï¼Œæ‚¨éšæ—¶å¯ä»¥æå–ã€‚_"
        )
        update.message.reply_text(help_txt, parse_mode=ParseMode.MARKDOWN_V2)
        return

    sub_cmd = args[0].lower()
    
    if sub_cmd == 'add':
        if len(args) < 2:
            update.message.reply_text("ç”¨æ³•: `/monitor add <query>`")
            return
        query_text = " ".join(args[1:])
        # ç”Ÿæˆç®€çŸ­ID
        task_id = hashlib.md5(query_text.encode()).hexdigest()[:8]
        
        if task_id in MONITOR_TASKS:
            # ä¿®æ”¹ç‚¹ï¼šå°† ( ) æ”¹ä¸º \( \)
            update.message.reply_text(f"âš ï¸ ä»»åŠ¡å·²å­˜åœ¨ \(ID: `{task_id}`\)", parse_mode=ParseMode.MARKDOWN_V2)
            return
            
        MONITOR_TASKS[task_id] = {
            "query": query_text,
            "chat_id": update.effective_chat.id,
            "added_at": int(time.time()),
            "last_run": 0,
            "interval": 3600, # åˆå§‹1å°æ—¶
            "status": "active",
            "unnotified_count": 0, # æ–°å¢ï¼šæœªé€šçŸ¥è®¡æ•°å™¨
            "notification_threshold": 5000 # æ–°å¢ï¼šé€šçŸ¥é˜ˆå€¼
        }
        save_monitor_tasks()
        
        # ç«‹å³å¯åŠ¨ç¬¬ä¸€æ¬¡è°ƒåº¦ (Use Jitter 0 for first run)
        context.job_queue.run_once(run_monitor_execution_job, 1, context={"task_id": task_id}, name=f"monitor_{task_id}")
        update.message.reply_text(f"âœ… ç›‘æ§é›·è¾¾å·²å¯åŠ¨\nID: `{task_id}`\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\n\næ•°æ®å°†è‡ªåŠ¨æ²‰æ·€ï¼Œä½¿ç”¨ `/monitor get {task_id}` æå–ã€‚", parse_mode=ParseMode.MARKDOWN_V2)

    elif sub_cmd == 'list':
        if not MONITOR_TASKS:
            update.message.reply_text("ğŸ“­ å½“å‰æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä»»åŠ¡ã€‚")
            return
        msg = ["*ğŸ“¡ æ´»è·ƒç›‘æ§ä»»åŠ¡*"]
        for tid, task in MONITOR_TASKS.items():
            if task.get('status') != 'active': continue
            
            # ç»Ÿè®¡æœ¬åœ°æ•°æ®
            data_file = os.path.join(MONITOR_DATA_DIR, f"{tid}.txt")
            count = 0
            if os.path.exists(data_file):
                try: 
                    with open(data_file, 'r', encoding='utf-8') as f: count = sum(1 for _ in f)
                except: pass
                
            last_run_str = "ç­‰å¾…ä¸­"
            if task.get('last_run'):
                dt = datetime.fromtimestamp(task['last_run']).replace(tzinfo=tz.tzlocal())
                last_run_str = dt.strftime('%H:%M')
            
            # å°†intervalè½¬æ¢ä¸ºåˆ†é’Ÿæˆ–å°æ—¶æ˜¾ç¤º
            interval = task.get('interval', 3600)
            if interval < 3600: dur = f"{interval//60}åˆ†"
            else: dur = f"{interval/3600:.1f}å°æ—¶"

            msg.append(f"ğŸ“¡ `{tid}`: *{escape_markdown_v2(task['query'][:25] + '...')}*")
            msg.append(f"   ğŸ“¦ åº“å­˜: *{count}* \\| â± ä¸Šæ¬¡: {last_run_str} \\| â³ é¢‘ç‡: {escape_markdown_v2(dur)}")
            msg.append("") # Spacer
            
        update.message.reply_text("\n".join(msg), parse_mode=ParseMode.MARKDOWN_V2)

    elif sub_cmd == 'del':
        if len(args) < 2: 
            update.message.reply_text("ç”¨æ³•: `/monitor del <task_id>`")
            return
        tid = args[1]
        if tid in MONITOR_TASKS:
            # å–æ¶ˆç°æœ‰ Job
            for job in context.job_queue.get_jobs_by_name(f"monitor_{tid}"):
                job.schedule_removal()
                
            del MONITOR_TASKS[tid]
            save_monitor_tasks()
            
            # åˆ é™¤æ•°æ®æ–‡ä»¶? (ä¿ç•™æ•°æ®æ›´å®‰å…¨ï¼Œåªåˆ ä»»åŠ¡)
            update.message.reply_text(f"ğŸ—‘ï¸ ä»»åŠ¡ `{tid}` å·²åœæ­¢å¹¶ç§»é™¤é…ç½®ã€‚", parse_mode=ParseMode.MARKDOWN_V2)
        else:
            update.message.reply_text("âŒ ä»»åŠ¡IDä¸å­˜åœ¨ã€‚")

    elif sub_cmd == 'get':
        if len(args) < 2:
            update.message.reply_text("ç”¨æ³•: `/monitor get <task_id>`") 
            return
        tid = args[1]
        
        # å³ä½¿ä»»åŠ¡ä¸åœ¨ config ä¸­ï¼Œåªè¦æœ‰æ–‡ä»¶ä¹Ÿå¯ä»¥å–ï¼ˆé˜²æ„å¤–åˆ é™¤ï¼‰
        data_file = os.path.join(MONITOR_DATA_DIR, f"{tid}.txt")
        if not os.path.exists(data_file):
            if tid not in MONITOR_TASKS:
                update.message.reply_text("âŒ æ‰¾ä¸åˆ°è¯¥IDçš„ä»»åŠ¡è®°å½•æˆ–æ•°æ®æ–‡ä»¶ã€‚")
            else:
                update.message.reply_text("ğŸ¤·â€â™€ï¸ è¯¥ä»»åŠ¡æš‚æ— ä»»ä½•æ•°æ®æ²‰æ·€ã€‚")
            return
            
        task_info = MONITOR_TASKS.get(tid, {})
        q_info = task_info.get('query', 'æœªçŸ¥æŸ¥è¯¢')
        
        send_file_safely(context, update.effective_chat.id, data_file, caption=f"ğŸ“¦ ç›‘æ§æ•°æ®å¯¼å‡º\nID: `{tid}`\nQuery: `{escape_markdown_v2(q_info)}`", parse_mode=ParseMode.MARKDOWN_V2)
        upload_and_send_links(context, update.effective_chat.id, data_file)
        
    else:
        update.message.reply_text("âŒ æœªçŸ¥å‘½ä»¤ã€‚è¯·ä½¿ç”¨ `/monitor` æŸ¥çœ‹å¸®åŠ©ã€‚")

def run_monitor_execution_job(context: CallbackContext):
    """è‡ªé€‚åº”ç›‘æ§é›·è¾¾æ ¸å¿ƒé€»è¾‘ (v2)"""
    job_context = context.job.context
    task_id = job_context.get('task_id')
    
    if task_id not in MONITOR_TASKS: return
    task = MONITOR_TASKS[task_id]
    
    query_text = task['query']
    os.makedirs(MONITOR_DATA_DIR, exist_ok=True)
    db_file = os.path.join(MONITOR_DATA_DIR, f"{task_id}.txt")
    
    # 1. è½½å…¥æœ¬åœ°æ•°æ®åº“å“ˆå¸Œ
    known_hashes = set()
    if os.path.exists(db_file):
        try:
            with open(db_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line: known_hashes.add(hashlib.md5(line.encode()).hexdigest())
        except Exception as e:
            logger.error(f"è¯»å–ç›‘æ§æ•°æ®åº“å¤±è´¥: {e}")

    # 2. æ‰§è¡Œæ•°æ®æ”¶é›† (ç”±â€œæ¢æµ‹â€æ”¹ä¸ºâ€œæ”¶é›†â€)
    fetch_func = lambda k, kl, ps: fetch_fofa_data(k, query_text, page=1, page_size=5000, fields="host", proxy_session=ps)
    data, _, _, _, _, error = execute_query_with_fallback(fetch_func)
    
    new_data_lines = []
    if not error and data and data.get('results'):
        results = data.get('results')
        for item in results:
            line_str = item[0] if isinstance(item, list) else str(item)
            line_str = line_str.strip()
            if not line_str: continue
            h = hashlib.md5(line_str.encode()).hexdigest()
            if h not in known_hashes:
                new_data_lines.append(line_str)
                known_hashes.add(h) # åœ¨ä¼šè¯ä¸­ä¹Ÿæ·»åŠ ï¼Œé˜²æ­¢å•æ¬¡æŸ¥è¯¢å†…é‡å¤
                
    # 3. æ™ºèƒ½è°ƒé¢‘ä¸é€šçŸ¥
    num_new_found = len(new_data_lines)
    current_interval = task.get('interval', 3600)
    unnotified_count = task.get('unnotified_count', 0)
    notification_threshold = task.get('notification_threshold', 5000)

    if num_new_found > 0:
        # å‘ç°æ–°ç›®æ ‡ï¼Œå†™å…¥æ•°æ®åº“
        with open(db_file, 'a', encoding='utf-8') as f:
            f.write("\n".join(new_data_lines) + "\n")
        
        unnotified_count += num_new_found
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é€šçŸ¥é˜ˆå€¼
        if unnotified_count >= notification_threshold:
            try:
                chat_id = task.get('chat_id')
                if chat_id:
                    notif_text = (
                        f"ğŸ“¡ *ç›‘æ§é›·è¾¾å‘½ä¸­* \\(Task: `{task_id}`\\)\n"
                        f"æŸ¥è¯¢: `{escape_markdown_v2(query_text[:30])}`\\.\\.\\.\n"
                        f"å‘ç° *{unnotified_count}* ä¸ªæ–°ç›®æ ‡\!\n"
                        f"å·²æ²‰æ·€è‡³æœ¬åœ°åº“ï¼Œå¯ä½¿ç”¨ `/monitor get {task_id}` æå–\\."
                    )
                    context.bot.send_message(chat_id, notif_text, parse_mode=ParseMode.MARKDOWN_V2)
                    unnotified_count = 0 # é‡ç½®è®¡æ•°å™¨
            except Exception as e:
                logger.error(f"å‘é€ç›‘æ§é€šçŸ¥å¤±è´¥: {e}")

        # æ™ºèƒ½è°ƒé¢‘ï¼šæ ¹æ®æœ¬æ¬¡å‘ç°æ•°é‡è°ƒæ•´ä¸‹æ¬¡é—´éš”
        if num_new_found < 100: # å°‘é‡å‘ç°ï¼Œè¯´æ˜ä¸æ˜¯çˆ†å‘æœŸ
            new_interval = min(43200, int(current_interval * 1.2)) # ç¨å¾®å»¶é•¿
        else: # å¤§é‡å‘ç°ï¼Œè¯´æ˜æ˜¯çˆ†å‘æœŸ
            new_interval = max(600, int(current_interval * 0.7)) # ç¼©çŸ­é—´éš”
    else:
        # æ— æ–°æ•°æ®ï¼Œè¿›å…¥å†·å´ï¼Œå»¶é•¿é—´éš”
        new_interval = min(43200, int(current_interval * 1.5))

    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
    task['last_run'] = int(time.time())
    task['interval'] = new_interval
    task['unnotified_count'] = unnotified_count
    save_monitor_tasks()
    
    # 4. å®‰æ’ä¸‹ä¸€æ¬¡è¿è¡Œ (åŠ å…¥æŠ–åŠ¨ï¼Œå¹¶å¤„ç† RuntimeError)
    jitter = random.randint(int(-new_interval * 0.1), int(new_interval * 0.1))
    next_run_delay = new_interval + jitter
    
    try:
        context.job_queue.run_once(run_monitor_execution_job, next_run_delay, context={"task_id": task_id}, name=f"monitor_{task_id}")
    except RuntimeError as e:
        logger.warning(f"æ— æ³•å®‰æ’æ–°çš„ç›‘æ§ä»»åŠ¡ (å¯èƒ½æ­£åœ¨å…³é—­): {e}")

# --- æ ¸å¿ƒå‘½ä»¤å¤„ç† ---
def start_command(update: Update, context: CallbackContext):
    user = update.effective_user
    welcome_text = f'ğŸ‘‹ æ¬¢è¿, {user.first_name}ï¼\nè¯·é€‰æ‹©ä¸€ä¸ªæ“ä½œ:'
    update.message.reply_text(welcome_text, reply_markup=reply_markup)

    if not CONFIG['admins']:
        first_admin_id = update.effective_user.id
        CONFIG.setdefault('admins', []).append(first_admin_id)
        save_config()
        update.message.reply_text(f"â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨ (ID: `{first_admin_id}`) æ·»åŠ ä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜ã€‚")

def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ v10\\.9*\n\n"
                  "*ğŸ” èµ„äº§æœç´¢ \\(å¸¸è§„\\)*\n`/kkfofa [key] <query>`\n_FOFAæœç´¢, é€‚ç”¨äº1ä¸‡æ¡ä»¥å†…æ•°æ®_\n\n"
                  "*ğŸšš èµ„äº§æœç´¢ \\(æµ·é‡\\)*\n`/allfofa <query>`\n_ä½¿ç”¨nextæ¥å£ç¨³å®šè·å–æµ·é‡æ•°æ® \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“¦ ä¸»æœºè¯¦æŸ¥ \\(æ™ºèƒ½\\)*\n`/host <ip|domain>`\n_è‡ªé€‚åº”è·å–æœ€å…¨ä¸»æœºä¿¡æ¯ \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ”¬ ä¸»æœºé€ŸæŸ¥ \\(èšåˆ\\)*\n`/lowhost <ip|domain> [detail]`\n_å¿«é€Ÿè·å–ä¸»æœºèšåˆä¿¡æ¯ \\(æ‰€æœ‰ç”¨æˆ·\\)_\n\n"
                  "*ğŸ“Š èšåˆç»Ÿè®¡*\n`/stats <query>`\n_è·å–å…¨å±€èšåˆç»Ÿè®¡ \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ*\n`/batchfind`\n_ä¸Šä¼ IPåˆ—è¡¨, åˆ†æç‰¹å¾å¹¶ç”ŸæˆExcel \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º \\(äº¤äº’å¼\\)*\n`/batch <query>`\n_è¿›å…¥äº¤äº’å¼èœå•é€‰æ‹©å­—æ®µå¯¼å‡º \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings`\n_è¿›å…¥äº¤äº’å¼è®¾ç½®èœå• \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ”‘ Keyç®¡ç†*\n`/batchcheckapi`\n_ä¸Šä¼ æ–‡ä»¶æ‰¹é‡éªŒè¯API Key \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/check` \\- ç³»ç»Ÿè‡ªæ£€\n"
                  "`/update` \\- åœ¨çº¿æ›´æ–°è„šæœ¬\n"
                  "`/shutdown` \\- å®‰å…¨å…³é—­/é‡å¯\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` \\- ç´§æ€¥åœæ­¢ä¸‹è½½ä»»åŠ¡\n`/cancel` \\- å–æ¶ˆå½“å‰æ“ä½œ" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN_V2)
def cancel(update: Update, context: CallbackContext) -> int:
    message = "æ“ä½œå·²å–æ¶ˆã€‚"
    if update.message: update.message.reply_text(message)
    elif update.callback_query: update.callback_query.edit_message_text(message)
    context.user_data.clear()
    return ConversationHandler.END

# --- /kkfofa, /allfofa & è®¿å®¢é€»è¾‘ ---
def query_entry_point(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    query_obj = update.callback_query
    message_obj = update.message

    if query_obj:
        query_obj.answer()
        context.user_data['command'] = '/kkfofa'
        
        if not is_admin(user_id):
            guest_key = ANONYMOUS_KEYS.get(str(user_id))
            if not guest_key:
                query_obj.message.edit_text("ğŸ‘‹ æ¬¢è¿ï¼ä½œä¸ºé¦–æ¬¡ä½¿ç”¨çš„è®¿å®¢ï¼Œè¯·å…ˆå‘é€æ‚¨çš„FOFA API Keyã€‚")
                return ConversationHandler.END
            context.user_data['guest_key'] = guest_key

        try:
            preset_index = int(query_obj.data.replace("run_preset_", ""))
            preset = CONFIG["presets"][preset_index]
            context.user_data['original_query'] = preset['query']
            context.user_data['key_index'] = None
            keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
            query_obj.message.edit_text(f"é¢„è®¾æŸ¥è¯¢: `{escape_markdown_v2(preset['query'])}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
            return QUERY_STATE_ASK_CONTINENT
        except (ValueError, IndexError):
            query_obj.message.edit_text("âŒ é¢„è®¾æŸ¥è¯¢å¤±è´¥ã€‚")
            return ConversationHandler.END

    elif message_obj:
        command = message_obj.text.split()[0].lower()

        if command == '/allfofa' and not is_admin(user_id):
            message_obj.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œ`/allfofa` å‘½ä»¤ä»…é™ç®¡ç†å‘˜ä½¿ç”¨ã€‚")
            return ConversationHandler.END

        if not is_admin(user_id):
            guest_key = ANONYMOUS_KEYS.get(str(user_id))
            if not guest_key:
                message_obj.reply_text("ğŸ‘‹ æ¬¢è¿ï¼ä½œä¸ºé¦–æ¬¡ä½¿ç”¨çš„è®¿å®¢ï¼Œè¯·è¾“å…¥æ‚¨çš„FOFA API Keyä»¥ç»§ç»­ã€‚æ‚¨çš„Keyåªä¼šè¢«æ‚¨è‡ªå·±ä½¿ç”¨ã€‚")
                if context.args:
                    context.user_data['pending_query'] = " ".join(context.args)
                return QUERY_STATE_GET_GUEST_KEY
            context.user_data['guest_key'] = guest_key

        if not context.args:
            if command == '/kkfofa':
                presets = CONFIG.get("presets", [])
                if not presets:
                    message_obj.reply_text(f"æ¬¢è¿ä½¿ç”¨FOFAæŸ¥è¯¢æœºå™¨äººã€‚\n\nâ¡ï¸ ç›´æ¥è¾“å…¥æŸ¥è¯¢è¯­æ³•: `/kkfofa domain=\"example.com\"`\nâ„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æŸ¥è¯¢ã€‚ç®¡ç†å‘˜å¯é€šè¿‡ /settings æ·»åŠ ã€‚")
                    return ConversationHandler.END
                keyboard = []
                for i, p in enumerate(presets):
                    query_preview = p['query'][:25] + '...' if len(p['query']) > 25 else p['query']
                    keyboard.append([InlineKeyboardButton(f"{p['name']} (`{query_preview}`)", callback_data=f"run_preset_{i}")])
                message_obj.reply_text("ğŸ‘‡ è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾æŸ¥è¯¢:", reply_markup=InlineKeyboardMarkup(keyboard))
            else:
                 message_obj.reply_text(f"ç”¨æ³•: `{command} <fofa_query>`")
            return ConversationHandler.END

        key_index, query_text = None, " ".join(context.args)
        if context.args[0].isdigit() and is_admin(user_id):
            try:
                num = int(context.args[0])
                if 1 <= num <= len(CONFIG['apis']):
                    key_index = num
                    query_text = " ".join(context.args[1:])
            except ValueError:
                pass
        
        context.user_data['original_query'] = query_text
        context.user_data['key_index'] = key_index
        context.user_data['command'] = command

        keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
        message_obj.reply_text(f"æŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
        return QUERY_STATE_ASK_CONTINENT

    
    else:
        logger.error("query_entry_point called with an unsupported update type.")
        return ConversationHandler.END

def get_guest_key(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    guest_key = update.message.text.strip()
    msg = update.message.reply_text("â³ æ­£åœ¨éªŒè¯æ‚¨çš„API Key...")
    data, error = verify_fofa_api(guest_key)
    if error:
        msg.edit_text(f"âŒ KeyéªŒè¯å¤±è´¥: {error}\nè¯·é‡æ–°è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„Keyï¼Œæˆ–ä½¿ç”¨ /cancel å–æ¶ˆã€‚")
        return QUERY_STATE_GET_GUEST_KEY
    ANONYMOUS_KEYS[str(user_id)] = guest_key
    save_anonymous_keys()
    msg.edit_text(f"âœ… KeyéªŒè¯æˆåŠŸ ({data.get('username', 'N/A')})ï¼æ‚¨çš„Keyå·²ä¿å­˜ï¼Œç°åœ¨å¯ä»¥å¼€å§‹æŸ¥è¯¢äº†ã€‚")
    if 'pending_query' in context.user_data:
        context.args = context.user_data.pop('pending_query').split()
        return query_entry_point(update, context)
    return ConversationHandler.END

def ask_continent_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    command = context.user_data['command']

    if choice == 'skip':
        context.user_data['query'] = context.user_data['original_query']
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown_v2(context.user_data['query'])}`", parse_mode=ParseMode.MARKDOWN_V2)
        if command == '/kkfofa':
            return proceed_with_kkfofa_query(update, context, message_to_edit=query.message)
        elif command == '/allfofa':
            return start_allfofa_search(update, context, message_to_edit=query.message)
    elif choice == 'select':
        keyboard = [
            [InlineKeyboardButton("ğŸŒ äºšæ´²", callback_data="continent_Asia"), InlineKeyboardButton("ğŸŒ æ¬§æ´²", callback_data="continent_Europe")],
            [InlineKeyboardButton("ğŸŒ åŒ—ç¾æ´²", callback_data="continent_NorthAmerica"), InlineKeyboardButton("ğŸŒ å—ç¾æ´²", callback_data="continent_SouthAmerica")],
            [InlineKeyboardButton("ğŸŒ éæ´²", callback_data="continent_Africa"), InlineKeyboardButton("ğŸŒ å¤§æ´‹æ´²", callback_data="continent_Oceania")],
            [InlineKeyboardButton("â†©ï¸ è·³è¿‡", callback_data="continent_skip")]]
        query.message.edit_text("è¯·é€‰æ‹©ä¸€ä¸ªå¤§æ´²:", reply_markup=InlineKeyboardMarkup(keyboard)); return QUERY_STATE_CONTINENT_CHOICE


def continent_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); continent = query.data.split('_', 1)[1]; original_query = context.user_data['original_query']
    command = context.user_data['command']

    if continent == 'skip':
        context.user_data['query'] = original_query
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown_v2(original_query)}`", parse_mode=ParseMode.MARKDOWN_V2)
    else:
        country_list = CONTINENT_COUNTRIES.get(continent)
        if not country_list: query.message.edit_text("âŒ é”™è¯¯ï¼šæ— æ•ˆçš„å¤§æ´²é€‰é¡¹ã€‚"); return ConversationHandler.END
        country_fofa_string = " || ".join([f'country="{code}"' for code in country_list]); final_query = f"({original_query}) && ({country_fofa_string})"
        context.user_data['query'] = final_query
        query.message.edit_text(f"æŸ¥è¯¢å·²æ„å»º:\n`{escape_markdown_v2(final_query)}`\n\næ­£åœ¨å¤„ç†\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)

    if command == '/kkfofa':
        return proceed_with_kkfofa_query(update, context, message_to_edit=query.message)
    elif command == '/allfofa':
        return start_allfofa_search(update, context, message_to_edit=query.message)

def proceed_with_kkfofa_query(update: Update, context: CallbackContext, message_to_edit):
    query_text = context.user_data['query']
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        message_text = (f"âœ… *å‘ç°ç¼“å­˜*\n\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nç¼“å­˜äº: *{escape_markdown_v2(time_str)}*\n\n")
        keyboard = []; is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        if is_expired or not is_admin(update.effective_user.id):
             message_text += "âš ï¸ *æ­¤ç¼“å­˜å·²è¿‡æœŸæˆ–æ‚¨æ˜¯è®¿å®¢ï¼Œæ— æ³•å¢é‡æ›´æ–°\\.*" if is_expired else ""
             keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else: 
            message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"; keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')]); keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        message_to_edit.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
        return QUERY_STATE_CACHE_CHOICE
    return start_new_kkfofa_search(update, context, message_to_edit=message_to_edit)

def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.message.edit_text("â¬‡ï¸ æ­£åœ¨ä»æœ¬åœ°ç¼“å­˜å‘é€æ–‡ä»¶..."); file_path = cached_item['cache']['file_path']
            send_file_safely(context, update.effective_chat.id, file_path, filename=os.path.basename(file_path))
            upload_and_send_links(context, update.effective_chat.id, file_path)
            query.message.delete()
        else: query.message.edit_text("âŒ æ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return start_new_kkfofa_search(update, context, message_to_edit=query.message)
    elif choice == 'incremental': query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data); query.message.delete(); return ConversationHandler.END
    elif choice == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END

def start_new_kkfofa_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index'); add_or_update_query(query_text)
    msg_text = f"ğŸ”„ æ­£åœ¨å¯¹ `{escape_markdown_v2(query_text)}` æ‰§è¡Œå…¨æ–°æŸ¥è¯¢\\.\\.\\."
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text(msg_text, parse_mode=ParseMode.MARKDOWN_V2)
    if message_to_edit: msg.edit_text(msg_text, parse_mode=ParseMode.MARKDOWN_V2)
    
    guest_key = context.user_data.get('guest_key')
    if guest_key:
        data, error = fetch_fofa_data(guest_key, query_text, page_size=1, fields="host")
        used_key_info = "æ‚¨çš„Key"
    else:
        data, _, used_key_index, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page_size=1, fields="host", proxy_session=proxy_session),
            preferred_key_index=key_index
        )
        used_key_info = f"Key \\[\\#{used_key_index}\\]"
    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id, 'is_batch_mode': False})
    
    success_message = f"âœ… ä½¿ç”¨ {used_key_info} æ‰¾åˆ° {total_size} æ¡ç»“æœ\\."
    
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
        start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [
            [InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½ (å‰1ä¸‡)", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ åˆ†ç‰‡ä¸‹è½½ (çªç ´ä¸Šé™)", callback_data='mode_sharding')],
            [InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback'), InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]
        ]
        
        msg_text = (
            f"{success_message}\n"
            f"æ£€æµ‹åˆ°å¤§é‡ç»“æœ \\({total_size}æ¡\\)\\ã€‚ç”±äºå•æ¬¡æŸ¥è¯¢ä¸Šé™ \\(10,000\\)ï¼Œæ‚¨å¯ä»¥ï¼š\n\n"
            f"1ï¸âƒ£ *å‰1ä¸‡*ï¼šä»…ä¸‹è½½æœ€è¿‘çš„1ä¸‡æ¡\\ã€‚\n"
            f"2ï¸âƒ£ *åˆ†ç‰‡ä¸‹è½½*ï¼šæŒ‰å›½å®¶è‡ªåŠ¨æ‹†åˆ†ï¼Œå°½å¯èƒ½é€šè¿‡ç§¯å°‘æˆå¤šçªç ´1ä¸‡æ¡é™åˆ¶ \\(æ¶ˆè€—æ›´å¤šè¯·æ±‚\\)\\ã€‚\n"
            f"3ï¸âƒ£ *æ·±åº¦è¿½æº¯*ï¼šæŒ‰æ—¶é—´å›æº¯ \\(éœ€é«˜ç­‰çº§Key\\)\\ã€‚"
        )
        msg.edit_text(msg_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
        return QUERY_STATE_KKFOFA_MODE 

def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); mode = query.data.split('_')[1]
    if mode == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    
    if mode == 'sharding':
        if context.user_data.get('is_batch_mode'):
             query.message.edit_text("âš ï¸ æŠ±æ­‰ï¼Œåˆ†ç‰‡ä¸‹è½½ç›®å‰ä»…æ”¯æŒåŸºç¡€ Host å¯¼å‡ºï¼Œä¸æ”¯æŒè‡ªå®šä¹‰æ‰¹é‡å­—æ®µã€‚")
             return ConversationHandler.END
        start_download_job(context, run_sharded_download_job, context.user_data)
        query.message.delete()
        return ConversationHandler.END

    if mode == 'traceback':
        keyboard = [[InlineKeyboardButton("â™¾ï¸ å…¨éƒ¨è·å–", callback_data='limit_none')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='limit_cancel')]]
        query.message.edit_text("è¯·è¾“å…¥æ·±åº¦è¿½æº¯è·å–çš„ç»“æœæ•°é‡ä¸Šé™ (ä¾‹å¦‚: 50000)ï¼Œæˆ–é€‰æ‹©å…¨éƒ¨è·å–ã€‚", reply_markup=InlineKeyboardMarkup(keyboard))
        return BATCH_STATE_GET_LIMIT if context.user_data.get('is_batch_mode') else QUERY_STATE_GET_TRACEBACK_LIMIT
    job_func = run_batch_download_query if context.user_data.get('is_batch_mode') else run_full_download_query
    if mode == 'full' and job_func:
        query.message.edit_text(f"â³ å¼€å§‹ä¸‹è½½..."); start_download_job(context, job_func, context.user_data); query.message.delete()
    return ConversationHandler.END

def get_traceback_limit(update: Update, context: CallbackContext):
    limit = None
    if update.callback_query:
        query = update.callback_query; query.answer()
        if query.data == 'limit_cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    elif update.message:
        try:
            limit = int(update.message.text.strip()); assert limit > 0
        except (ValueError, AssertionError):
            update.message.reply_text("âŒ æ— æ•ˆçš„æ•°å­—ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚")
            return BATCH_STATE_GET_LIMIT if context.user_data.get('is_batch_mode') else QUERY_STATE_GET_TRACEBACK_LIMIT
    context.user_data['limit'] = limit
    job_func = run_batch_traceback_query if context.user_data.get('is_batch_mode') else run_traceback_download_query
    msg_target = update.callback_query.message if update.callback_query else update.message
    msg_target.reply_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ (ä¸Šé™: {limit or 'æ— '})...")
    start_download_job(context, job_func, context.user_data)
    if update.callback_query: msg_target.delete()
    return ConversationHandler.END

# --- /host å’Œ /lowhost å‘½ä»¤ ---
def _create_dict_from_fofa_result(result_list, fields_list):
    return {fields_list[i]: result_list[i] for i in range(len(fields_list))}
def get_common_host_info(results, fields_list):
    if not results: return {}
    first_entry = _create_dict_from_fofa_result(results[0], fields_list)
    info = {
        "IP": first_entry.get('ip', 'N/A'),
        "åœ°ç†ä½ç½®": f"{first_entry.get('country_name', '')} {first_entry.get('region', '')} {first_entry.get('city', '')}".strip(),
        "ASN": f"{first_entry.get('asn', 'N/A')} ({first_entry.get('org', 'N/A')})",
        "æ“ä½œç³»ç»Ÿ": first_entry.get('os', 'N/A'),
    }
    port_index = fields_list.index('port') if 'port' in fields_list else -1
    if port_index != -1:
        all_ports = sorted(list(set(res[port_index] for res in results if len(res) > port_index)))
        info["å¼€æ”¾ç«¯å£"] = all_ports
    return info
def create_host_summary(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    summary = [f"ğŸ“Œ *ä¸»æœºæ¦‚è§ˆ: `{escape_markdown_v2(host_arg)}`*"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                summary.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(', '.join(map(str, value)))}`")
            else:
                summary.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(value)}`")
    summary.append("\nğŸ“„ *è¯¦ç»†æŠ¥å‘Šå·²ä½œä¸ºæ–‡ä»¶å‘é€\\.*")
    return "\n".join(summary)
def format_full_host_report(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    report = [f"ğŸ“Œ *ä¸»æœºèšåˆæŠ¥å‘Š: `{escape_markdown_v2(host_arg)}`*\n"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                report.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(', '.join(map(str, value)))}`")
            else:
                report.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(value)}`")
    report.append("\n\-\-\- *æœåŠ¡è¯¦æƒ…* \-\-\-\n")
    for res_list in results:
        d = _create_dict_from_fofa_result(res_list, fields_list)
        port_info = [f"ğŸŒ *Port `{d.get('port')}` \\({escape_markdown_v2(d.get('protocol', 'N/A'))}\\)*"]
        if d.get('title'): port_info.append(f"  \- *æ ‡é¢˜:* `{escape_markdown_v2(d.get('title'))}`")
        if d.get('server'): port_info.append(f"  \- *æœåŠ¡:* `{escape_markdown_v2(d.get('server'))}`")
        if d.get('icp'): port_info.append(f"  \- *ICP:* `{escape_markdown_v2(d.get('icp'))}`")
        if d.get('jarm'): port_info.append(f"  \- *JARM:* `{escape_markdown_v2(d.get('jarm'))}`")
        cert_str = d.get('cert', '{}')
        try:
            cert_info = json.loads(cert_str) if isinstance(cert_str, str) and cert_str.startswith('{') else {}
            if cert_info.get('issuer', {}).get('CN'): port_info.append(f"  \- *è¯ä¹¦é¢å‘è€…:* `{escape_markdown_v2(cert_info['issuer']['CN'])}`")
            if cert_info.get('subject', {}).get('CN'): port_info.append(f"  \- *è¯ä¹¦ä½¿ç”¨è€…:* `{escape_markdown_v2(cert_info['subject']['CN'])}`")
        except json.JSONDecodeError:
            pass
        if d.get('header'): port_info.append(f"  \- *Header:* ```\n{d.get('header')}\n```")
        if d.get('banner'): port_info.append(f"  \- *Banner:* ```\n{d.get('banner')}\n```")
        report.append("\n".join(port_info))
    return "\n".join(report)
def host_command_logic(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text(f"ç”¨æ³•: `/host <ip_or_domain>`\n\nç¤ºä¾‹:\n`/host 1\\.1\\.1\\.1`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    host_arg = context.args[0]
    processing_message = update.message.reply_text(f"â³ æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown_v2(host_arg)}`\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    query = f'ip="{host_arg}"' if re.match(r"^\d{1,3}(\.\d{1,3}){3}$", host_arg) else f'domain="{host_arg}"'
    data, final_fields_list, error = None, [], None
    for level in range(3, -1, -1): 
        fields_to_try = get_fields_by_level(level)
        fields_str = ",".join(fields_to_try)
        try:
            processing_message.edit_text(f"â³ æ­£åœ¨å°è¯•ä»¥ *ç­‰çº§ {level}* å­—æ®µæŸ¥è¯¢\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
        except (BadRequest, RetryAfter, TimedOut):
            time.sleep(1)
        temp_data, _, _, _, _, temp_error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query, page_size=100, fields=fields_str, proxy_session=proxy_session)
        )
        if not temp_error:
            data = temp_data
            final_fields_list = fields_to_try
            error = None
            break
        if "[820001]" not in str(temp_error):
            error = temp_error
            break
        else:
            error = temp_error
            continue
    if error:
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{escape_markdown_v2(error)}`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    raw_results = data.get('results', [])
    if not raw_results:
        processing_message.edit_text(f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown_v2(host_arg)}` çš„ä»»ä½•ä¿¡æ¯\\.", parse_mode=ParseMode.MARKDOWN_V2)
        return
    
    unique_services = {}
    ip_idx = final_fields_list.index('ip') if 'ip' in final_fields_list else -1
    port_idx = final_fields_list.index('port') if 'port' in final_fields_list else -1
    protocol_idx = final_fields_list.index('protocol') if 'protocol' in final_fields_list else -1
    
    if port_idx != -1 and protocol_idx != -1:
        for res in raw_results:
            key = (res[ip_idx] if ip_idx != -1 else host_arg, res[port_idx], res[protocol_idx])
            if key not in unique_services:
                unique_services[key] = res
        results = list(unique_services.values())
    else:
        results = raw_results

    full_report = format_full_host_report(host_arg, results, final_fields_list)
    if len(full_report) > 3800:
        summary_report = create_host_summary(host_arg, results, final_fields_list)
        processing_message.edit_text(summary_report, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
        report_filename = f"host_details_{host_arg.replace('.', '_')}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', full_report)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename, caption="ğŸ“„ å®Œæ•´çš„è¯¦ç»†æŠ¥å‘Šå·²é™„ä¸Šã€‚")
            upload_and_send_links(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        processing_message.edit_text(full_report, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
@admin_only
def host_command(update: Update, context: CallbackContext):
    host_command_logic(update, context)
def format_host_summary(data):
    parts = [f"ğŸ“Œ *ä¸»æœºèšåˆæ‘˜è¦: `{escape_markdown_v2(data.get('host', 'N/A'))}`*"]
    if data.get('ip'): parts.append(f"*IP:* `{escape_markdown_v2(data.get('ip'))}`")
    location = f"{data.get('country_name', '')} {data.get('region', '')} {data.get('city', '')}".strip()
    if location: parts.append(f"*ä½ç½®:* `{escape_markdown_v2(location)}`")
    if data.get('asn'): parts.append(f"*ASN:* `{data.get('asn')} \\({escape_markdown_v2(data.get('org', 'N/A'))}\\)`")
    
    if data.get('ports'):
        port_list = data.get('ports', [])
        if port_list and isinstance(port_list[0], dict):
            port_numbers = sorted([p.get('port') for p in port_list if p.get('port')])
            parts.append(f"*å¼€æ”¾ç«¯å£:* `{escape_markdown_v2(', '.join(map(str, port_numbers)))}`")
        else:
            parts.append(f"*å¼€æ”¾ç«¯å£:* `{escape_markdown_v2(', '.join(map(str, port_list)))}`")

    if data.get('protocols'): parts.append(f"*åè®®:* `{escape_markdown_v2(', '.join(data.get('protocols', [])))}`")
    if data.get('category'): parts.append(f"*èµ„äº§ç±»å‹:* `{escape_markdown_v2(', '.join(data.get('category', [])))}`")
    if data.get('products'):
        product_names = [p.get('name', 'N/A') for p in data.get('products', [])]
        parts.append(f"*äº§å“/ç»„ä»¶:* `{escape_markdown_v2(', '.join(product_names))}`")
    return "\n".join(parts)
def format_host_details(data):
    summary = format_host_summary(data)
    details = ["\n\-\-\- *ç«¯å£è¯¦æƒ…* \-\-\-"]
    for port_info in data.get('port_details', []):
        port_str = f"\nğŸŒ *Port `{port_info.get('port')}` \\({escape_markdown_v2(port_info.get('protocol', 'N/A'))}\\)*"
        # ä¿®æ”¹ç‚¹ï¼šå°†æ‰€æœ‰çš„ - æ”¹ä¸º \-
        if port_info.get('product'): port_str += f"\n  \- *äº§å“:* `{escape_markdown_v2(port_info.get('product'))}`"
        if port_info.get('title'): port_str += f"\n  \- *æ ‡é¢˜:* `{escape_markdown_v2(port_info.get('title'))}`"
        if port_info.get('jarm'): port_str += f"\n  \- *JARM:* `{escape_markdown_v2(port_info.get('jarm'))}`"
        if port_info.get('banner'): port_str += f"\n  \- *Banner:* ```\n{port_info.get('banner')}\n```"        
        details.append(port_str)
    full_report = summary + "\n".join(details)
    return full_report
def lowhost_command(update: Update, context: CallbackContext) -> None:
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/lowhost <ip_or_domain> [detail]`\n\nç¤ºä¾‹:\n`/lowhost 1\\.1\\.1\\.1`\n`/lowhost example\\.com detail`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    host = context.args[0]
    detail = len(context.args) > 1 and context.args[1].lower() == 'detail'
    processing_message = update.message.reply_text(f"æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown_v2(host)}` çš„èšåˆä¿¡æ¯\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_host_info(key, host, detail, proxy_session=proxy_session)
    )
    if error:
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{escape_markdown_v2(error)}`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    if not data:
        processing_message.edit_text(f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown_v2(host)}` çš„ä»»ä½•ä¿¡æ¯\\.", parse_mode=ParseMode.MARKDOWN_V2)
        return
    if detail:
        formatted_text = format_host_details(data)
    else:
        formatted_text = format_host_summary(data)
    if len(formatted_text) > 3800:
        processing_message.edit_text("æŠ¥å‘Šè¿‡é•¿ï¼Œå°†ä½œä¸ºæ–‡ä»¶å‘é€ã€‚")
        report_filename = f"lowhost_details_{host.replace('.', '_')}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', formatted_text)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename, caption="ğŸ“„ å®Œæ•´çš„èšåˆæŠ¥å‘Šå·²é™„ä¸Šã€‚")
            upload_and_send_links(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        processing_message.edit_text(formatted_text, parse_mode=ParseMode.MARKDOWN_V2)

# --- /stats å‘½ä»¤ ---
@admin_only
def stats_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("è¯·è¾“å…¥è¦è¿›è¡Œèšåˆç»Ÿè®¡çš„FOFAæŸ¥è¯¢è¯­æ³•:")
        return STATS_STATE_GET_QUERY
    return get_fofa_stats_query(update, context)
def get_fofa_stats_query(update: Update, context: CallbackContext):
    query_text = " ".join(context.args) if context.args else update.message.text
    msg = update.message.reply_text(f"â³ æ­£åœ¨å¯¹ `{escape_markdown_v2(query_text)}` è¿›è¡Œèšåˆç»Ÿè®¡\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_stats(key, query_text, proxy_session=proxy_session)
    )
    
    if error:
        msg.edit_text(f"âŒ ç»Ÿè®¡å¤±è´¥: {escape_markdown_v2(error)}", parse_mode=ParseMode.MARKDOWN_V2)
        return ConversationHandler.END

    # æ™ºèƒ½é€‚é…å±‚ï¼šå¤„ç†åµŒå¥—å’Œæ‰å¹³ä¸¤ç§APIå“åº”æ ¼å¼
    stats_source = data.get("aggs", data)

    report = [f"ğŸ“Š *èšåˆç»Ÿè®¡æŠ¥å‘Š for `{escape_markdown_v2(query_text)}`*\n"]
    
    # å®Œæ•´ç‰ˆ display_mapï¼ŒåŒ…å«å…¨éƒ¨12ä¸ªå¯èšåˆå­—æ®µ
    display_map = {
        "countries": "ğŸŒ Top 5 å›½å®¶/åœ°åŒº",
        "org": "ğŸ¢ Top 5 ç»„ç»‡ (ORG)",
        "asn": "ğŸ“› Top 5 ASN",
        "server": "ğŸ–¥ï¸ Top 5 æœåŠ¡/ç»„ä»¶",
        "protocol": "ğŸ”Œ Top 5 åè®®",
        "port": "ğŸšª Top 5 ç«¯å£",
        "icp": "ğŸ“œ Top 5 ICPå¤‡æ¡ˆ",
        "title": "ğŸ“° Top 5 ç½‘ç«™æ ‡é¢˜",
        "fid": "ğŸ”‘ Top 5 FID æŒ‡çº¹",
        "domain": "ğŸŒ Top 5 åŸŸå",          # <-- æ–°å¢
        "os": "ğŸ’» Top 5 æ“ä½œç³»ç»Ÿ",        # <-- æ–°å¢
        "asset_type": "ğŸ“¦ Top 5 èµ„äº§ç±»å‹" # <-- æ–°å¢
    }
    
    data_found = False
    for key, title in display_map.items():
        items = stats_source.get(key)
        
        if items and isinstance(items, list):
            data_found = True
            report.append(f"*{escape_markdown_v2(title)}*:")
            for item in items[:5]:
                name = escape_markdown_v2(item.get('name', 'N/A'))
                count = item.get('count', 0)
                report.append(f"  `{name}`: *{count:,}*")
            report.append("")

    if not data_found:
        report.append("_æœªæ‰¾åˆ°å¯ä¾›èšåˆçš„æ•°æ®ã€‚_")

    try:
        msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2)
    except BadRequest as e:
        if "message is too long" in str(e).lower():
            msg.edit_text("âœ… ç»Ÿè®¡å®Œæˆï¼æŠ¥å‘Šè¿‡é•¿ï¼Œå°†ä½œä¸ºæ–‡ä»¶å‘é€ã€‚")
            report_filename = f"stats_report_{int(time.time())}.txt"
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', "\n".join(report))
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename)
            os.remove(report_filename)
        else:
            msg.edit_text(f"âŒ å‘é€æŠ¥å‘Šæ—¶å‡ºé”™: {escape_markdown_v2(str(e))}", parse_mode=ParseMode.MARKDOWN_V2)

    return ConversationHandler.END

def inline_fofa_handler(update: Update, context: CallbackContext) -> None:
    """å¤„ç†å†…è”æŸ¥è¯¢è¯·æ±‚"""
    query_text = update.inline_query.query
    results = []

    try:
        # å¦‚æœç”¨æˆ·åªè¾“å…¥äº†@botnameï¼Œæ²¡æœ‰é™„å¸¦æŸ¥è¯¢è¯­å¥
        if not query_text:
            results.append(
                InlineQueryResultArticle(
                    id=str(uuid.uuid4()),
                    title="å¼€å§‹è¾“å…¥FOFAæŸ¥è¯¢è¯­æ³•...",
                    description='ä¾‹å¦‚: domain="example.com"',
                    input_message_content=InputTextMessageContent(
                        "ğŸ’¡ **FOFA å†…è”æŸ¥è¯¢ç”¨æ³•** ğŸ’¡\n\n"
                        "åœ¨ä»»ä½•èŠå¤©æ¡†ä¸­è¾“å…¥ `@ä½ çš„æœºå™¨äººç”¨æˆ·å` ç„¶åè·Ÿä¸ŠFOFAæŸ¥è¯¢è¯­æ³•ï¼Œå³å¯å¿«é€Ÿæœç´¢ã€‚\n\n"
                        "ä¾‹å¦‚ï¼š`@ä½ çš„æœºå™¨äººç”¨æˆ·å domain=\"qq.com\"`",
                        parse_mode=ParseMode.MARKDOWN
                    )
                )
            )
            update.inline_query.answer(results, cache_time=300) # åˆå§‹æ¶ˆæ¯å¯ä»¥ç¼“å­˜ä¹…ä¸€ç‚¹
            return

        # --- ç”¨æˆ·è¾“å…¥äº†æŸ¥è¯¢è¯­å¥ï¼Œå¼€å§‹è°ƒç”¨FOFA API ---
        def inline_query_logic(key, key_level, proxy_session):
            return fetch_fofa_data(key, query_text, page_size=10, fields="host,title", proxy_session=proxy_session)

        data, _, _, _, _, error = execute_query_with_fallback(inline_query_logic)

        # å¦‚æœæŸ¥è¯¢å‡ºé”™
        if error:
            results.append(
                InlineQueryResultArticle(
                    id='error',
                    title="æŸ¥è¯¢å‡ºé”™",
                    description=str(error),
                    input_message_content=InputTextMessageContent(f"FOFA æŸ¥è¯¢å¤±è´¥: {error}")
                )
            )
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æœ
        elif not data or not data.get('results'):
            results.append(
                InlineQueryResultArticle(
                    id='no_results',
                    title="æœªæ‰¾åˆ°ç»“æœ",
                    description=f"æŸ¥è¯¢: {query_text}",
                    input_message_content=InputTextMessageContent(f"å¯¹äºæŸ¥è¯¢ '{query_text}'ï¼ŒFOFA æœªè¿”å›ä»»ä½•ç»“æœã€‚")
                )
            )
        # æˆåŠŸæ‰¾åˆ°ç»“æœ
        else:
            for result in data['results']:
                host = result[0] if result and len(result) > 0 else "N/A"
                title = result[1] if result and len(result) > 1 else "æ— æ ‡é¢˜"
                
                results.append(
                    InlineQueryResultArticle(
                        id=str(uuid.uuid4()),
                        title=host,
                        description=title,
                        input_message_content=InputTextMessageContent(host)
                    )
                )
    
    except Exception as e:
        # æ•è·ä»»ä½•æ„å¤–çš„å´©æºƒï¼Œå¹¶è¿”å›é”™è¯¯ä¿¡æ¯
        logger.error(f"å†…è”æŸ¥è¯¢æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        results = [
            InlineQueryResultArticle(
                id='critical_error',
                title="æœºå™¨äººå†…éƒ¨é”™è¯¯",
                description="å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚",
                input_message_content=InputTextMessageContent("æœºå™¨äººå†…éƒ¨é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
            )
        ]
    
    # ç¡®ä¿æ€»èƒ½å“åº”Telegramï¼Œé¿å…ç•Œé¢å¡ä½
    update.inline_query.answer(results, cache_time=10) # å®é™…æŸ¥è¯¢ç»“æœç¼“å­˜æ—¶é—´çŸ­ä¸€ç‚¹


# --- /batchfind å‘½ä»¤ ---
BATCH_FEATURES = { "protocol": "åè®®", "domain": "åŸŸå", "os": "æ“ä½œç³»ç»Ÿ", "server": "æœåŠ¡/ç»„ä»¶", "icp": "ICPå¤‡æ¡ˆå·", "title": "æ ‡é¢˜", "jarm": "JARMæŒ‡çº¹", "cert.issuer.org": "è¯ä¹¦é¢å‘ç»„ç»‡", "cert.issuer.cn": "è¯ä¹¦é¢å‘CN", "cert.subject.org": "è¯ä¹¦ä¸»ä½“ç»„ç»‡", "cert.subject.cn": "è¯ä¹¦ä¸»ä½“CN" }
@admin_only
def batchfind_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« IP:Port åˆ—è¡¨çš„ .txt æ–‡ä»¶ã€‚")
    return BATCHFIND_STATE_GET_FILE
def get_batch_file_handler(update: Update, context: CallbackContext):
    doc = update.message.document
    file = doc.get_file()
    file_path = os.path.join(FOFA_CACHE_DIR, doc.file_name)
    file.download(custom_path=file_path)
    context.user_data['batch_file_path'] = file_path
    context.user_data['selected_features'] = set()
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = [InlineKeyboardButton(f"â˜ {features_list[i][1]}", callback_data=f"batchfeature_{features_list[i][0]}")]
        if i + 1 < len(features_list):
            row.append(InlineKeyboardButton(f"â˜ {features_list[i+1][1]}", callback_data=f"batchfeature_{features_list[i+1][0]}"))
        keyboard.append(row)
    keyboard.append([InlineKeyboardButton("âœ… å…¨éƒ¨é€‰æ‹©", callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    update.message.reply_text("è¯·é€‰æ‹©æ‚¨éœ€è¦åˆ†æçš„ç‰¹å¾:", reply_markup=InlineKeyboardMarkup(keyboard))
    return BATCHFIND_STATE_SELECT_FEATURES
def select_batch_features_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); feature = query.data.split('_', 1)[1]
    selected = context.user_data['selected_features']
    if feature == 'done':
        if not selected: query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ï¼", show_alert=True); return BATCHFIND_STATE_SELECT_FEATURES
        query.message.edit_text("âœ… ç‰¹å¾é€‰æ‹©å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°åˆ†æã€‚")
        job_context = {'chat_id': query.message.chat_id, 'file_path': context.user_data['batch_file_path'], 'features': list(selected)}
        context.job_queue.run_once(run_batch_find_job, 1, context=job_context, name=f"batchfind_{query.message.chat_id}")
        return ConversationHandler.END
    if feature == 'all':
        if len(selected) == len(BATCH_FEATURES): selected.clear()
        else: selected.update(BATCH_FEATURES.keys())
    elif feature in selected: selected.remove(feature)
    else: selected.add(feature)
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = []
        key1 = features_list[i][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key1 in selected else 'â˜'} {features_list[i][1]}", callback_data=f"batchfeature_{key1}"))
        if i + 1 < len(features_list):
            key2 = features_list[i+1][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key2 in selected else 'â˜'} {features_list[i+1][1]}", callback_data=f"batchfeature_{key2}"))
        keyboard.append(row)
    all_text = "âœ… å–æ¶ˆå…¨é€‰" if len(selected) == len(BATCH_FEATURES) else "âœ… å…¨éƒ¨é€‰æ‹©"
    keyboard.append([InlineKeyboardButton(all_text, callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    query.message.edit_reply_markup(reply_markup=InlineKeyboardMarkup(keyboard))
    return BATCHFIND_STATE_SELECT_FEATURES
def run_batch_find_job(context: CallbackContext):
    job_data = context.job.context; chat_id, file_path, features = job_data['chat_id'], job_data['file_path'], job_data['features']
    bot = context.bot; msg = bot.send_message(chat_id, "â³ å¼€å§‹æ‰¹é‡åˆ†æä»»åŠ¡...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f: targets = [line.strip() for line in f if line.strip()]
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); return
    if not targets: msg.edit_text("âŒ æ–‡ä»¶ä¸ºç©ºã€‚"); return
    total_targets = len(targets); processed_count = 0; detailed_results_for_excel = []
    for target in targets:
        processed_count += 1
        if processed_count % 10 == 0:
            try: msg.edit_text(f"åˆ†æè¿›åº¦: {create_progress_bar(processed_count/total_targets*100)} ({processed_count}/{total_targets})")
            except (BadRequest, RetryAfter, TimedOut): pass
        query = f'ip="{target}"' if ':' not in target else f'host="{target}"'
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query, page_size=1, fields=",".join(features), proxy_session=proxy_session)
        )
        if not error and data.get('results'):
            result = data['results'][0]
            row_data = {'Target': target}
            row_data.update({BATCH_FEATURES.get(f, f): result[i] for i, f in enumerate(features)})
            detailed_results_for_excel.append(row_data)
    if detailed_results_for_excel:
        try:
            df = pd.DataFrame(detailed_results_for_excel)
            excel_filename = generate_filename_from_query(os.path.basename(file_path), prefix="analysis", ext=".xlsx")
            df.to_excel(excel_filename, index=False, engine='openpyxl')
            msg.edit_text("âœ… åˆ†æå®Œæˆï¼æ­£åœ¨å‘é€ExcelæŠ¥å‘Š...")
            send_file_safely(context, chat_id, excel_filename, caption="ğŸ“„ è¯¦ç»†ç‰¹å¾åˆ†æExcelæŠ¥å‘Š")
            upload_and_send_links(context, chat_id, excel_filename)
            os.remove(excel_filename)
        except Exception as e: msg.edit_text(f"âŒ ç”ŸæˆExcelå¤±è´¥: {e}")
    else: msg.edit_text("ğŸ¤·â€â™€ï¸ åˆ†æå®Œæˆï¼Œä½†æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„FOFAæ•°æ®ã€‚")
    if os.path.exists(file_path): os.remove(file_path)

# --- /batch (äº¤äº’å¼) ---
def build_batch_fields_keyboard(user_data):
    selected_fields = user_data.get('selected_fields', set())
    page = user_data.get('page', 0)
    flat_fields = []
    for category, fields in FIELD_CATEGORIES.items():
        for field in fields:
            flat_fields.append((field, category))
    items_per_page = 12
    start_index = page * items_per_page
    end_index = start_index + items_per_page
    page_items = flat_fields[start_index:end_index]
    keyboard = []
    for i in range(0, len(page_items), 2):
        row = []
        field1, cat1 = page_items[i]
        prefix1 = "â˜‘ï¸" if field1 in selected_fields else "â˜"
        row.append(InlineKeyboardButton(f"{prefix1} {field1}", callback_data=f"batchfield_toggle_{field1}"))
        if i + 1 < len(page_items):
            field2, cat2 = page_items[i+1]
            prefix2 = "â˜‘ï¸" if field2 in selected_fields else "â˜"
            row.append(InlineKeyboardButton(f"{prefix2} {field2}", callback_data=f"batchfield_toggle_{field2}"))
        keyboard.append(row)
    nav_row = []
    if page > 0:
        nav_row.append(InlineKeyboardButton("â¬…ï¸ ä¸Šä¸€é¡µ", callback_data="batchfield_prev"))
    if end_index < len(flat_fields):
        nav_row.append(InlineKeyboardButton("ä¸‹ä¸€é¡µ â¡ï¸", callback_data="batchfield_next"))
    keyboard.append(nav_row)
    keyboard.append([InlineKeyboardButton("âœ… å®Œæˆé€‰æ‹©å¹¶å¼€å§‹", callback_data="batchfield_done")])
    return InlineKeyboardMarkup(keyboard)
@admin_only
def batch_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/batch <fofa_query>`")
        return ConversationHandler.END
    query_text = " ".join(context.args)
    context.user_data['query'] = query_text
    context.user_data['selected_fields'] = set(FREE_FIELDS[:5])
    context.user_data['page'] = 0
    keyboard = build_batch_fields_keyboard(context.user_data)
    update.message.reply_text(f"æŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„å­—æ®µ:", reply_markup=keyboard, parse_mode=ParseMode.MARKDOWN_V2)
    return BATCH_STATE_SELECT_FIELDS
def batch_select_fields_callback(update: Update, context: CallbackContext):
    query = update.callback_query
    query.answer()
    action = query.data.split('_', 1)[1]
    if action == "next":
        context.user_data['page'] += 1
    elif action == "prev":
        context.user_data['page'] -= 1
    elif action.startswith("toggle_"):
        field = action.replace("toggle_", "")
        if field in context.user_data['selected_fields']:
            context.user_data['selected_fields'].remove(field)
        else:
            context.user_data['selected_fields'].add(field)
    elif action == "done":
        selected_fields = context.user_data.get('selected_fields')
        if not selected_fields:
            query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µï¼", show_alert=True)
            return BATCH_STATE_SELECT_FIELDS
        query_text = context.user_data['query']
        fields_str = ",".join(list(selected_fields))
        msg = query.message.edit_text("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢ä»¥é¢„ä¼°æ•°æ®é‡...")
        data, _, used_key_index, key_level, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page_size=1, fields="host", proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
        total_size = data.get('size', 0)
        if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
        allowed_fields = get_fields_by_level(key_level)
        unauthorized_fields = [f for f in selected_fields if f not in allowed_fields]
        if unauthorized_fields:
            msg.edit_text(f"âš ï¸ è­¦å‘Š: æ‚¨é€‰æ‹©çš„å­—æ®µ `{', '.join(unauthorized_fields)}` è¶…å‡ºå½“å‰å¯ç”¨æœ€é«˜çº§Key (ç­‰çº§{key_level}) çš„æƒé™ã€‚è¯·é‡æ–°é€‰æ‹©æˆ–å‡çº§Keyã€‚")
            return BATCH_STATE_SELECT_FIELDS
        context.user_data.update({'chat_id': update.effective_chat.id, 'fields': fields_str, 'total_size': total_size, 'is_batch_mode': True })
        success_message = f"âœ… ä½¿ç”¨ Key \\[\\#{used_key_index}\\] \\(ç­‰çº§{key_level}\\) æ‰¾åˆ° {total_size} æ¡ç»“æœ\\."
        if total_size <= 10000:
            msg.edit_text(f"{success_message}\nå¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡º\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2); start_download_job(context, run_batch_download_query, context.user_data)
            return ConversationHandler.END
        else:
            keyboard = [[InlineKeyboardButton("ğŸ’ å¯¼å‡ºå‰1ä¸‡æ¡", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯å¯¼å‡º", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
            msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©å¯¼å‡ºæ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2); return BATCH_STATE_MODE_CHOICE
    keyboard = build_batch_fields_keyboard(context.user_data)
    query.message.edit_reply_markup(reply_markup=keyboard)
    return BATCH_STATE_SELECT_FIELDS

# --- /batchcheckapi å‘½ä»¤ ---
@admin_only
def batch_check_api_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« API Keys çš„ .txt æ–‡ä»¶ (æ¯è¡Œä¸€ä¸ª Key)ã€‚")
    return BATCHCHECKAPI_STATE_GET_FILE
def receive_api_file(update: Update, context: CallbackContext) -> int:
    doc = update.message.document
    if not doc.file_name.endswith('.txt'):
        update.message.reply_text("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼  .txt æ–‡ä»¶ã€‚")
        return ConversationHandler.END
    file = doc.get_file()
    temp_path = os.path.join(FOFA_CACHE_DIR, f"api_check_{doc.file_id}.txt")
    file.download(custom_path=temp_path)
    try:
        with open(temp_path, 'r', encoding='utf-8') as f:
            keys_to_check = [line.strip() for line in f if line.strip()]
    except Exception as e:
        update.message.reply_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
        return ConversationHandler.END
    if not keys_to_check:
        update.message.reply_text("ğŸ¤·â€â™€ï¸ æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«ä»»ä½•æœ‰æ•ˆçš„ Keyã€‚")
        if os.path.exists(temp_path): os.remove(temp_path)
        return ConversationHandler.END
    msg = update.message.reply_text(f"â³ å¼€å§‹æ‰¹é‡éªŒè¯ {len(keys_to_check)} ä¸ª API Key...")
    valid_keys, invalid_keys = [], []
    total = len(keys_to_check)
    for i, key in enumerate(keys_to_check):
        data, error = verify_fofa_api(key)
        if not error:
            is_vip = data.get('isvip', False)
            api_level = data.get('vip_level', 0)
            level = 0
            if is_vip:
                if api_level == 2: level = 1
                elif api_level == 3: level = 2
                elif api_level >= 4: level = 3
                else: level = 1
            level_name = {0: "å…è´¹", 1: "ä¸ªäºº", 2: "å•†ä¸š", 3: "ä¼ä¸š"}.get(level, "æœªçŸ¥")
            valid_keys.append(f"`...{key[-4:]}` \\- âœ… *æœ‰æ•ˆ* \\({escape_markdown_v2(data.get('username', 'N/A'))}, {level_name}ä¼šå‘˜\\)")
        else:
            invalid_keys.append(f"`...{key[-4:]}` \\- âŒ *æ— æ•ˆ* \\(åŸå› : {escape_markdown_v2(error)}\\)")
        if (i + 1) % 10 == 0 or (i + 1) == total:
            try:
                progress_text = f"â³ éªŒè¯è¿›åº¦: {create_progress_bar((i+1)/total*100)} ({i+1}/{total})"
                msg.edit_text(progress_text)
            except (BadRequest, RetryAfter, TimedOut):
                time.sleep(2)
    
    report = [f"ğŸ“‹ *æ‰¹é‡API KeyéªŒè¯æŠ¥å‘Š*"]
    report.append(f"\næ€»è®¡: {total} \\| æœ‰æ•ˆ: {len(valid_keys)} \\| æ— æ•ˆ: {len(invalid_keys)}\n")
    if valid_keys:
        report.append("\-\-\- *æœ‰æ•ˆ Keys* \-\-\-")
        report.extend(valid_keys)
    if invalid_keys:
        report.append("\n\-\-\- *æ— æ•ˆ Keys* \-\-\-")
        report.extend(invalid_keys)
    
    report_text = "\n".join(report)
    if len(report_text) > 3800:
        summary = f"âœ… éªŒè¯å®Œæˆï¼\næ€»è®¡: {total} \\| æœ‰æ•ˆ: {len(valid_keys)} \\| æ— æ•ˆ: {len(invalid_keys)}\n\næŠ¥å‘Šè¿‡é•¿ï¼Œå·²ä½œä¸ºæ–‡ä»¶å‘é€\\."
        msg.edit_text(summary)
        report_filename = f"api_check_report_{int(time.time())}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', report_text)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        msg.edit_text(report_text, parse_mode=ParseMode.MARKDOWN_V2)

    if os.path.exists(temp_path): os.remove(temp_path)
    return ConversationHandler.END

# --- å…¶ä»–ç®¡ç†å‘½ä»¤ ---
@admin_only
def check_command(update: Update, context: CallbackContext):
    msg = update.message.reply_text("â³ æ­£åœ¨æ‰§è¡Œç³»ç»Ÿè‡ªæ£€...")
    report = ["*ğŸ“‹ ç³»ç»Ÿè‡ªæ£€æŠ¥å‘Š*"]
    try:
        global CONFIG; CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
        report.append("âœ… *é…ç½®æ–‡ä»¶*: `config\\.json` åŠ è½½æ­£å¸¸")
    except Exception as e:
        report.append(f"âŒ *é…ç½®æ–‡ä»¶*: åŠ è½½å¤±è´¥ \\- {escape_markdown_v2(str(e))}")
        msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2); return
    report.append("\n*ğŸ”‘ API Keys:*")
    if not CONFIG.get('apis'): report.append("  \\- âš ï¸ æœªé…ç½®ä»»ä½• API Key")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            report.append(f"  `\\#{i+1}` \\(`...{key[-4:]}`\\): {level_name}")
    report.append("\n*ğŸŒ ä»£ç†:*")
    proxies_to_check = CONFIG.get("proxies", [])
    if not proxies_to_check and CONFIG.get("proxy"): proxies_to_check.append(CONFIG.get("proxy"))
    if not proxies_to_check: report.append("  \\- â„¹ï¸ æœªé…ç½®ä»£ç†")
    else:
        for p in proxies_to_check:
            try:
                requests.get("https://fofa.info", proxies={"http": p, "https": p}, timeout=10, verify=False)
                report.append(f"  \\- `{escape_markdown_v2(p)}`: âœ… è¿æ¥æˆåŠŸ")
            except Exception as e: report.append(f"  \\- `{escape_markdown_v2(p)}`: âŒ è¿æ¥å¤±è´¥ \\- `{escape_markdown_v2(str(e))}`")
    msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2)
@admin_only
def stop_all_tasks(update: Update, context: CallbackContext):
    chat_id = update.effective_chat.id
    context.bot_data[f'stop_job_{chat_id}'] = True
    update.message.reply_text("ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·ï¼Œå½“å‰ä¸‹è½½ä»»åŠ¡å°†åœ¨å®Œæˆæœ¬é¡µååœæ­¢ã€‚")
@super_admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if update.callback_query:
        update.callback_query.answer()
    chat_id = update.effective_chat.id
    backup_filename = f"fofabot_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
    
    json_files = glob.glob('*.json')
    if not json_files:
        context.bot.send_message(chat_id, "ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ä»»ä½• \\.json é…ç½®æ–‡ä»¶å¯ä»¥å¤‡ä»½ã€‚")
        return
        
    msg = context.bot.send_message(chat_id, f"ğŸ“¦ æ­£åœ¨æ‰“åŒ…æ‰€æœ‰ {len(json_files)} ä¸ª \\.json é…ç½®æ–‡ä»¶...")
    
    try:
        with zipfile.ZipFile(backup_filename, 'w', zipfile.ZIP_DEFLATED) as zf:
            for f in json_files:
                zf.write(f)
        
        msg.edit_text("âœ… æ‰“åŒ…å®Œæˆï¼Œæ­£åœ¨å‘é€å¤‡ä»½æ–‡ä»¶...")
        send_file_safely(context, chat_id, backup_filename, caption=f"FofaBot å®Œæ•´é…ç½®å¤‡ä»½({len(json_files)}ä¸ªæ–‡ä»¶)")
        upload_and_send_links(context, chat_id, backup_filename)
        os.remove(backup_filename)
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
        msg.edit_text(f"âŒ åˆ›å»ºå¤‡ä»½å‹ç¼©æ–‡ä»¶æ—¶å‡ºé”™: {escape_markdown_v2(str(e))}", parse_mode=ParseMode.MARKDOWN_V2)

@super_admin_only
def restore_config_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨çš„ `config.json` æˆ– `.zip` æ ¼å¼çš„å¤‡ä»½æ–‡ä»¶ã€‚")
    return RESTORE_STATE_GET_FILE
def receive_config_file(update: Update, context: CallbackContext):
    global CONFIG
    doc = update.message.document
    file_name = doc.file_name.lower()
    
    # æ¢å¤ .zip å¤‡ä»½
    if file_name.endswith('.zip'):
        msg = update.message.reply_text("è§£å‹å¹¶æ¢å¤ ZIP å¤‡ä»½ä¸­...")
        zip_path = os.path.join(FOFA_CACHE_DIR, doc.file_name)
        doc.get_file().download(custom_path=zip_path)
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zf:
                if 'config.json' not in zf.namelist():
                    msg.edit_text("âŒ å‹ç¼©åŒ…ä¸­ç¼ºå°‘ `config.json`ï¼Œæ¢å¤å¤±è´¥ã€‚")
                    return ConversationHandler.END
                
                zf.extractall('.')
            
            os.remove(zip_path)
            CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
            msg.edit_text("âœ… å·²ä»ZIPæˆåŠŸæ¢å¤æ‰€æœ‰é…ç½®æ–‡ä»¶ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ã€‚")
            shutdown_command(update, context, restart=True)
            
        except Exception as e:
            logger.error(f"æ¢å¤ZIPå¤‡ä»½æ—¶å‡ºé”™: {e}")
            msg.edit_text(f"âŒ æ¢å¤å¤‡ä»½å¤±è´¥: {escape_markdown_v2(str(e))}", parse_mode=ParseMode.MARKDOWN_V2)

        return ConversationHandler.END
    
    # æ¢å¤å•ä¸ª config.json
    elif file_name == 'config.json':
        doc.get_file().download(custom_path=CONFIG_FILE)
        CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
        update.message.reply_text("âœ… é…ç½®æ–‡ä»¶å·²æ¢å¤ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ã€‚")
        shutdown_command(update, context, restart=True)
        return ConversationHandler.END

    else:
        update.message.reply_text("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼  `config.json` æˆ– `.zip` å¤‡ä»½æ–‡ä»¶ã€‚")
        return ConversationHandler.END
@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("æŸ¥è¯¢å†å²ä¸ºç©ºã€‚"); return
    history_text = "*ğŸ•°ï¸ æœ€è¿‘æŸ¥è¯¢å†å²*\n\n"
    for i, item in enumerate(HISTORY['queries'][:15]):
        dt_utc = datetime.fromisoformat(item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        history_text += f"`{i+1}\\.` `{escape_markdown_v2(item['query_text'])}`\n   _{escape_markdown_v2(time_str)}_\n"
    update.message.reply_text(history_text, parse_mode=ParseMode.MARKDOWN_V2)
@admin_only
def import_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨è¦å¯¼å…¥çš„æ—§ç¼“å­˜æ–‡ä»¶ (txtæ ¼å¼)ã€‚")
    return IMPORT_STATE_GET_FILE
def get_import_query(update: Update, context: CallbackContext):
    doc = update.message.document
    if not doc.file_name.endswith('.txt'): update.message.reply_text("âŒ è¯·ä¸Šä¼  .txt æ–‡ä»¶ã€‚"); return ConversationHandler.END
    file = doc.get_file()
    temp_path = os.path.join(FOFA_CACHE_DIR, f"import_{doc.file_id}.txt")
    file.download(custom_path=temp_path)
    try:
        with open(temp_path, 'r', encoding='utf-8') as f: result_count = sum(1 for _ in f)
    except Exception as e: update.message.reply_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); os.remove(temp_path); return ConversationHandler.END
    query_text = update.message.text
    if not query_text: update.message.reply_text("è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„åŸå§‹FOFAæŸ¥è¯¢è¯­æ³•:"); return IMPORT_STATE_GET_FILE
    final_filename = generate_filename_from_query(query_text)
    final_path = os.path.join(FOFA_CACHE_DIR, final_filename)
    shutil.move(temp_path, final_path)
    cache_data = {'file_path': final_path, 'result_count': result_count}
    add_or_update_query(query_text, cache_data)
    update.message.reply_text(f"âœ… æˆåŠŸå¯¼å…¥ç¼“å­˜ï¼\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nå…± {result_count} æ¡è®°å½•\\.", parse_mode=ParseMode.MARKDOWN_V2)
    return ConversationHandler.END
@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE):
        send_file_safely(context, update.effective_chat.id, LOG_FILE)
        upload_and_send_links(context, update.effective_chat.id, LOG_FILE)
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")

@super_admin_only
def shutdown_command(update: Update, context: CallbackContext, restart=False):
    message = "ğŸ¤– æœºå™¨äººæ­£åœ¨é‡å¯..." if restart else "ğŸ¤– æœºå™¨äººæ­£åœ¨å…³é—­..."
    update.message.reply_text(message)
    logger.info(f"Shutdown/Restart initiated by user {update.effective_user.id}")
    
    # v10.9 FIX: Use OS signals for a truly robust and deadlock-free shutdown.
    # This sends a SIGINT signal (like Ctrl+C) to the bot's own process,
    # which updater.idle() is designed to catch gracefully.
    threading.Thread(target=lambda: (time.sleep(1), os.kill(os.getpid(), signal.SIGINT))).start()

@super_admin_only
def update_script_command(update: Update, context: CallbackContext):
    update_url = CONFIG.get("update_url")
    if not update_url:
        update.message.reply_text("âŒ æœªåœ¨è®¾ç½®ä¸­é…ç½®æ›´æ–°URLã€‚è¯·ä½¿ç”¨ /settings \\-\\> è„šæœ¬æ›´æ–° \\-\\> è®¾ç½®URLã€‚")
        return
    msg = update.message.reply_text("â³ æ­£åœ¨ä»è¿œç¨‹URLä¸‹è½½æ–°è„šæœ¬...")
    try:
        response = requests.get(update_url, timeout=30, proxies=get_proxies())
        response.raise_for_status()
        script_content = response.text
        with open(__file__, 'w', encoding='utf-8') as f:
            f.write(script_content)
        msg.edit_text("âœ… è„šæœ¬æ›´æ–°æˆåŠŸï¼æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ–°ç‰ˆæœ¬ã€‚")
        shutdown_command(update, context, restart=True)
    except Exception as e:
        msg.edit_text(f"âŒ æ›´æ–°å¤±è´¥: {escape_markdown_v2(str(e))}", parse_mode=ParseMode.MARKDOWN_V2)

# --- è®¾ç½®èœå• ---
@super_admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api'), InlineKeyboardButton("âœ¨ é¢„è®¾ç®¡ç†", callback_data='settings_preset')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†æ± ç®¡ç†", callback_data='settings_proxypool'), InlineKeyboardButton("ğŸ“¡ ç›‘æ§è®¾ç½®", callback_data='settings_monitor')],
        [InlineKeyboardButton("ğŸ“¤ ä¸Šä¼ æ¥å£è®¾ç½®", callback_data='settings_upload'), InlineKeyboardButton("ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜è®¾ç½®", callback_data='settings_admin')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup'), InlineKeyboardButton("ğŸ”„ è„šæœ¬æ›´æ–°", callback_data='settings_update')],
        [InlineKeyboardButton("âŒ å…³é—­èœå•", callback_data='settings_close')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"; reply_markup = InlineKeyboardMarkup(keyboard)
    if update.callback_query: update.callback_query.message.edit_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2)
    else: update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_MAIN
def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': return show_api_menu(update, context, force_check=False)
    if menu == 'proxypool': return show_proxypool_menu(update, context)
    if menu == 'backup': return show_backup_restore_menu(update, context)
    if menu == 'preset': return show_preset_menu(update, context)
    if menu == 'monitor': return show_monitor_menu(update, context)
    if menu == 'update': return show_update_menu(update, context)
    if menu == 'upload': return show_upload_api_menu(update, context)
    if menu == 'admin': return show_admin_menu(update, context)
    if menu == 'close': query.message.edit_text("èœå•å·²å…³é—­."); return ConversationHandler.END
    return SETTINGS_STATE_ACTION
def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'add_api': query.message.edit_text("è¯·è¾“å…¥æ–°çš„FOFA API Key:"); return SETTINGS_STATE_GET_KEY
    if action == 'remove_api': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„API Keyçš„ç¼–å·:"); return SETTINGS_STATE_REMOVE_API
    if action == 'check_api': return show_api_menu(update, context, force_check=True)
    if action == 'back': return settings_command(update, context)
def show_api_menu(update: Update, context: CallbackContext, force_check=False):
    query = update.callback_query
    if force_check: 
        query.message.edit_text("â³ æ­£åœ¨é‡æ–°æ£€æŸ¥æ‰€æœ‰API KeyçŠ¶æ€...")
        check_and_classify_keys()
    api_list_text = ["*ğŸ”‘ å½“å‰ API Keys:*"]
    if not CONFIG['apis']: api_list_text.append("  \\- _ç©º_")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            api_list_text.append(f"  `\\#{i+1}` `...{key[-4:]}` \\- {level_name}")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='action_add_api'), InlineKeyboardButton("â– ç§»é™¤", callback_data='action_remove_api')],
        [InlineKeyboardButton("ğŸ”„ çŠ¶æ€æ£€æŸ¥", callback_data='action_check_api'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back')]
    ]
    query.message.edit_text("\n".join(api_list_text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_ACTION
def get_key(update: Update, context: CallbackContext):
    new_key = update.message.text.strip()
    if new_key in CONFIG['apis']:
        update.message.reply_text("âš ï¸ æ­¤ Key å·²å­˜åœ¨ã€‚")
        return settings_command(update, context)

    msg = update.message.reply_text("â³ æ­£åœ¨éªŒè¯æ–°çš„ API Key...")
    data, error = verify_fofa_api(new_key)
    if error:
        msg.edit_text(f"âŒ Key éªŒè¯å¤±è´¥: {error}\nè¯·é‡æ–°è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„Keyï¼Œæˆ–ä½¿ç”¨ /cancel å–æ¶ˆã€‚")
        return SETTINGS_STATE_GET_KEY  
    
    CONFIG['apis'].append(new_key)
    save_config()
    check_and_classify_keys() 
    msg.edit_text(f"âœ… API Key ({data.get('username', 'N/A')}) å·²æˆåŠŸæ·»åŠ ã€‚")
    
    # ä½¿ç”¨ä¸€ä¸ªæ–°çš„ update å¯¹è±¡æ¥è°ƒç”¨ settings_commandï¼Œå› ä¸ºå®ƒéœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ update å¯¹è±¡
    # æ¥å‘é€æ–°æ¶ˆæ¯ï¼Œè€Œæˆ‘ä»¬ç¼–è¾‘äº†æ—§æ¶ˆæ¯ã€‚
    fake_update = type('FakeUpdate', (), {'message': update.message, 'callback_query': None})
    return settings_command(fake_update, context)

def remove_api(update: Update, context: CallbackContext):
    input_text = update.message.text.strip()
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰æ•°å­—ï¼Œæ”¯æŒé€—å·ã€ç©ºæ ¼ç­‰åˆ†éš”ç¬¦
    indices_to_remove_str = re.findall(r'\d+', input_text)
    
    if not indices_to_remove_str:
        update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
        return settings_command(update, context)

    indices_to_remove = set()
    invalid_indices = []
    for index_str in indices_to_remove_str:
        try:
            index = int(index_str) - 1
            if 0 <= index < len(CONFIG['apis']):
                indices_to_remove.add(index)
            else:
                invalid_indices.append(index_str)
        except ValueError:
            invalid_indices.append(index_str)

    if invalid_indices:
        update.message.reply_text(f"âš ï¸ æ— æ•ˆçš„ç¼–å·: {', '.join(invalid_indices)}ã€‚")

    if not indices_to_remove:
        return settings_command(update, context)

    # å¯¹ç´¢å¼•è¿›è¡Œé™åºæ’åºï¼Œä»¥é˜²æ­¢åœ¨åˆ é™¤æ—¶å‡ºç°ç´¢å¼•é”™è¯¯
    sorted_indices = sorted(list(indices_to_remove), reverse=True)
    
    removed_keys_display = []
    for index in sorted_indices:
        removed_key = CONFIG['apis'].pop(index)
        # v10.9.6 FIX: æ‰‹åŠ¨è½¬ä¹‰Markdownå­—ç¬¦ä»¥ç”¨äºç¡®è®¤æ¶ˆæ¯ã€‚
        removed_keys_display.append(f"`...{removed_key[-4:]}` \\(åŸç¼–å· \\#{index + 1}\\)")

    save_config()
    check_and_classify_keys()
    
    update.message.reply_text(f"âœ… å·²æˆåŠŸç§»é™¤ä»¥ä¸‹ Key:\n{', '.join(reversed(removed_keys_display))}", parse_mode=ParseMode.MARKDOWN_V2)
    
    fake_update = type('FakeUpdate', (), {'message': update.message, 'callback_query': None})
    return settings_command(fake_update, context)
def show_preset_menu(update: Update, context: CallbackContext):
    query = update.callback_query; presets = CONFIG.get("presets", [])
    text = ["*âœ¨ é¢„è®¾æŸ¥è¯¢ç®¡ç†*"]
    if not presets: text.append("  \\- _ç©º_")
    else:
        for i, p in enumerate(presets): text.append(f"`{i+1}\\.` *{escape_markdown_v2(p['name'])}*: `{escape_markdown_v2(p['query'])}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='preset_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='preset_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='preset_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_PRESET_MENU
def preset_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥é¢„è®¾çš„åç§°:"); return SETTINGS_STATE_GET_PRESET_NAME
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„é¢„è®¾çš„ç¼–å·:"); return SETTINGS_STATE_REMOVE_PRESET
    if action == 'back': return settings_command(update, context)
def get_preset_name(update: Update, context: CallbackContext):
    context.user_data['preset_name'] = update.message.text.strip()
    update.message.reply_text("è¯·è¾“å…¥æ­¤é¢„è®¾çš„FOFAæŸ¥è¯¢è¯­æ³•:")
    return SETTINGS_STATE_GET_PRESET_QUERY
def get_preset_query(update: Update, context: CallbackContext):
    preset_query = update.message.text.strip(); preset_name = context.user_data['preset_name']
    CONFIG.setdefault("presets", []).append({"name": preset_name, "query": preset_query}); save_config()
    update.message.reply_text("âœ… é¢„è®¾å·²æ·»åŠ ã€‚")
    return settings_command(update, context)
def remove_preset(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['presets']):
            CONFIG['presets'].pop(index); save_config()
            update.message.reply_text("âœ… é¢„è®¾å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_update_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("update_url") or "æœªè®¾ç½®"
    text = f"ğŸ”„ *è„šæœ¬æ›´æ–°è®¾ç½®*\n\nå½“å‰æ›´æ–°URL: `{escape_markdown_v2(url)}`"
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®URL", callback_data='update_set_url'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='update_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_ACTION
def get_update_url(update: Update, context: CallbackContext):
    if not update.message or not update.message.text:
        return SETTINGS_STATE_GET_UPDATE_URL
        
    url = update.message.text.strip()
    if url.lower().startswith('http'): 
        CONFIG['update_url'] = url
        save_config()
        update.message.reply_text("âœ… æ›´æ–°URLå·²è®¾ç½®ã€‚")
    else: 
        update.message.reply_text("âŒ æ— æ•ˆçš„URLæ ¼å¼ã€‚")
    return settings_command(update, context)
def show_backup_restore_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    text = "ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\n\\- *å¤‡ä»½*: å‘é€å½“å‰çš„ `config\\.json` æ–‡ä»¶ç»™æ‚¨ã€‚\n\\- *æ¢å¤*: æ‚¨éœ€è¦å‘æœºå™¨äººå‘é€ä¸€ä¸ª `config\\.json` æ–‡ä»¶æ¥è¦†ç›–å½“å‰é…ç½®ã€‚"
    keyboard = [[InlineKeyboardButton("ğŸ“¤ å¤‡ä»½", callback_data='backup_now'), InlineKeyboardButton("ğŸ“¥ æ¢å¤", callback_data='restore_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='backup_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_ACTION
def show_proxypool_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    proxies = CONFIG.get("proxies", [])
    text = ["*ğŸŒ ä»£ç†æ± ç®¡ç†*"]
    if not proxies: text.append("  \\- _ç©º_")
    else:
        for i, p in enumerate(proxies): text.append(f"`{i+1}\\.` `{escape_markdown_v2(p)}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='proxypool_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='proxypool_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='proxypool_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_PROXYPOOL_MENU
def proxypool_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥è¦æ·»åŠ çš„ä»£ç† (æ ¼å¼: `http://user:pass@host:port`):"); return SETTINGS_STATE_GET_PROXY_ADD
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„ä»£ç†çš„ç¼–å·:"); return SETTINGS_STATE_GET_PROXY_REMOVE
    if action == 'back': return settings_command(update, context)
def get_proxy_to_add(update: Update, context: CallbackContext):
    proxy = update.message.text.strip()
    if proxy not in CONFIG['proxies']: CONFIG['proxies'].append(proxy); save_config(); update.message.reply_text("âœ… ä»£ç†å·²æ·»åŠ ã€‚")
    else: update.message.reply_text("âš ï¸ æ­¤ä»£ç†å·²å­˜åœ¨ã€‚")
    return settings_command(update, context)
def get_proxy_to_remove(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['proxies']):
            CONFIG['proxies'].pop(index); save_config()
            update.message.reply_text("âœ… ä»£ç†å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_upload_api_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("upload_api_url") or "æœªè®¾ç½®"
    token_status = "å·²è®¾ç½®" if CONFIG.get("upload_api_token") else "æœªè®¾ç½®"
    links_status = "âœ… æ˜¾ç¤º" if CONFIG.get("show_download_links", True) else "âŒ éšè—"
    
    text = (f"ğŸ“¤ *ä¸Šä¼ æ¥å£è®¾ç½®*\n\n"
            f"æ­¤åŠŸèƒ½å¯å°†ç”Ÿæˆæ–‡ä»¶ä¸Šä¼ åˆ°æ‚¨æŒ‡å®šçš„æœåŠ¡å™¨ï¼Œå¹¶è¿”å›ä¸‹è½½å‘½ä»¤ã€‚\n\n"
            f"*API URL:* `{escape_markdown_v2(url)}`\n"
            f"*API Token:* `{token_status}`\n"
            f"*ä¸‹è½½é“¾æ¥:* `{links_status}`")
    kbd = [
        [InlineKeyboardButton("âœï¸ è®¾ç½® URL", callback_data='upload_set_url'), InlineKeyboardButton("ğŸ”‘ è®¾ç½® Token", callback_data='upload_set_token')],
        [InlineKeyboardButton(f"ğŸ”— åˆ‡æ¢é“¾æ¥æ˜¾ç¤º", callback_data='upload_toggle_links')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='upload_back')]
    ]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(kbd), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_UPLOAD_API_MENU

def upload_api_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    
    if action == 'toggle_links':
        current_status = CONFIG.get("show_download_links", True)
        CONFIG["show_download_links"] = not current_status
        save_config()
        return show_upload_api_menu(update, context)
        
    if action == 'back': return settings_command(update, context)
    if action == 'set_url': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ URL:"); return SETTINGS_STATE_GET_UPLOAD_URL
    if action == 'set_token': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ Token:"); return SETTINGS_STATE_GET_UPLOAD_TOKEN
    return SETTINGS_STATE_UPLOAD_API_MENU
def get_upload_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.lower().startswith('http'):
        CONFIG['upload_api_url'] = url; save_config()
        update.message.reply_text("âœ… ä¸Šä¼  URL å·²æ›´æ–°ã€‚")
    else: update.message.reply_text("âŒ æ— æ•ˆçš„ URL æ ¼å¼ã€‚")
    return settings_command(update, context)
def get_upload_token(update: Update, context: CallbackContext):
    token = update.message.text.strip()
    CONFIG['upload_api_token'] = token; save_config()
    update.message.reply_text("âœ… ä¸Šä¼  Token å·²æ›´æ–°ã€‚")
    return settings_command(update, context)

# --- Admin Management ---
def show_admin_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    admins = CONFIG.get('admins', [])
    text = ["*ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜åˆ—è¡¨*"]
    if not admins:
        text.append("  \\- _ç©º_")
    else:
        for i, admin_id in enumerate(admins):
            user_label = "â­ è¶…çº§ç®¡ç†å‘˜" if i == 0 else f"  `\\#{i+1}`"
            text.append(f"{user_label} \\- `{admin_id}`")
    
    keyboard = []
    if is_super_admin(query.from_user.id):
        keyboard.append([
            InlineKeyboardButton("â• æ·»åŠ ç®¡ç†å‘˜", callback_data='admin_add'),
            InlineKeyboardButton("â– ç§»é™¤ç®¡ç†å‘˜", callback_data='admin_remove')
        ])
    keyboard.append([InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='admin_back')])
    
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_ADMIN_MENU

def admin_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query
    query.answer()
    action = query.data.split('_')[1]

    if not is_super_admin(query.from_user.id):
        query.answer("â›”ï¸ åªæœ‰è¶…çº§ç®¡ç†å‘˜æ‰èƒ½æ‰§è¡Œæ­¤æ“ä½œã€‚", show_alert=True)
        return SETTINGS_STATE_ADMIN_MENU


    if action == 'add':
        query.message.edit_text("è¯·è¾“å…¥æ–°ç®¡ç†å‘˜çš„ Telegram User ID:")
        return SETTINGS_STATE_GET_ADMIN_ID_TO_ADD

    if action == 'remove':
        query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„ç®¡ç†å‘˜çš„ç¼–å· (ä¾‹å¦‚: 2):")
        return SETTINGS_STATE_GET_ADMIN_ID_TO_REMOVE

    if action == 'back':
        return settings_command(update, context)

def get_admin_id_to_add(update: Update, context: CallbackContext):
    try:
        new_id = int(update.message.text.strip())
        admins = CONFIG.get('admins', [])
        if new_id in admins:
            update.message.reply_text("âš ï¸ æ­¤ç”¨æˆ·å·²ç»æ˜¯ç®¡ç†å‘˜ã€‚")
        else:
            CONFIG['admins'].append(new_id)
            save_config()
            update.message.reply_text("âœ… ç®¡ç†å‘˜å·²æ·»åŠ ã€‚")
    except ValueError:
        update.message.reply_text("âŒ æ— æ•ˆçš„ User IDï¼Œè¯·è¾“å…¥çº¯æ•°å­—ã€‚")
    
    return settings_command(update, context)

def get_admin_id_to_remove(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip())
        admins = CONFIG.get('admins', [])
        if index == 1:
            update.message.reply_text("âŒ ä¸èƒ½ç§»é™¤è¶…çº§ç®¡ç†å‘˜ã€‚")
        elif 1 < index <= len(admins):
            removed_admin = CONFIG['admins'].pop(index - 1)
            save_config()
            update.message.reply_text(f"âœ… å·²ç§»é™¤ç®¡ç†å‘˜ `{removed_admin}`ã€‚")
        else:
            update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError:
        update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    
    return settings_command(update, context)

# --- Monitor Settings Menu ---
def show_monitor_menu(update: Update, context: CallbackContext):
    query = getattr(update, 'callback_query', None)
    
    msg = ["*ğŸ“¡ ç›‘æ§ä»»åŠ¡ç®¡ç†*"]
    
    tasks = {k: v for k, v in MONITOR_TASKS.items() if v.get('status') == 'active'}
    
    if not tasks:
        msg.append("\n_å½“å‰æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä»»åŠ¡ã€‚_")
    else:
        for tid, task in tasks.items():
            data_file = os.path.join(MONITOR_DATA_DIR, f"{tid}.txt")
            count = 0
            if os.path.exists(data_file):
                try: 
                    with open(data_file, 'r', encoding='utf-8') as f: count = sum(1 for _ in f)
                except Exception: pass
            
            next_run_str = "æœªçŸ¥"
            jobs = context.job_queue.get_jobs_by_name(f"monitor_{tid}")
            if jobs:
                # Use next_t for next run time
                next_run_dt = jobs[0].next_t
                if isinstance(next_run_dt, datetime):
                     next_run_str = next_run_dt.astimezone(tz.tzlocal()).strftime('%H:%M:%S')
                else: 
                     next_run_str = "è®¡åˆ’ä¸­..."
            else:
                 last_run = task.get('last_run', 0)
                 if last_run == 0:
                     next_run_str = "é¦–æ¬¡è¿è¡Œ"
                 else:
                     next_run_str = "å·²æš‚åœ" 

            threshold = task.get('notification_threshold', 5000)
            
            query_preview = task['query']
            if len(query_preview) > 25: query_preview = query_preview[:25] + '...'
            
            msg.append(f"\nğŸ“¡ `{tid}`: *{escape_markdown_v2(query_preview)}*")
            msg.append(f"   ğŸ“¦ åº“å­˜: *{count}* \| é€šçŸ¥é˜ˆå€¼: *{threshold}*")
            msg.append(f"   â± ä¸‹æ¬¡è¿è¡Œ: *{next_run_str}*")

    keyboard = [
        [
            InlineKeyboardButton("â• æ·»åŠ ", callback_data='monitor_add'),
            InlineKeyboardButton("â– ç§»é™¤", callback_data='monitor_remove'),
            InlineKeyboardButton("âš™ï¸ é…ç½®", callback_data='monitor_config')
        ],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='monitor_back')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    if query:
        query.message.edit_text("\n".join(msg), reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
    elif update.message:
        update.message.reply_text("\n".join(msg), reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
        
    return SETTINGS_STATE_MONITOR_MENU

def monitor_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'back': return settings_command(update, context)
    if action == 'add': 
        query.message.edit_text("è¯·è¾“å…¥è¦æ·»åŠ çš„ç›‘æ§æŸ¥è¯¢è¯­å¥:"); 
        return SETTINGS_STATE_GET_MONITOR_QUERY_TO_ADD
    if action == 'remove': 
        query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„ç›‘æ§ä»»åŠ¡ID:"); 
        return SETTINGS_STATE_GET_MONITOR_ID_TO_REMOVE
    if action == 'config':
        query.message.edit_text("è¯·è¾“å…¥æ‚¨æƒ³é…ç½®çš„ç›‘æ§ä»»åŠ¡ID:")
        return SETTINGS_STATE_GET_MONITOR_ID_TO_CONFIG

def get_monitor_query_to_add(update: Update, context: CallbackContext):
    query_text = update.message.text.strip()
    task_id = hashlib.md5(query_text.encode()).hexdigest()[:8]
    if task_id in MONITOR_TASKS:
        update.message.reply_text(f"âš ï¸ ä»»åŠ¡å·²å­˜åœ¨ (ID: `{task_id}`)", parse_mode=ParseMode.MARKDOWN_V2)
    else:
        MONITOR_TASKS[task_id] = {
            "query": query_text, "chat_id": update.effective_chat.id,
            "added_at": int(time.time()), "last_run": 0, "interval": 3600,
            "status": "active", "unnotified_count": 0, "notification_threshold": 5000
        }
        save_monitor_tasks()
        context.job_queue.run_once(run_monitor_execution_job, 1, context={"task_id": task_id}, name=f"monitor_{task_id}")
        update.message.reply_text(f"âœ… ç›‘æ§å·²æ·»åŠ ï¼ŒID: `{task_id}`", parse_mode=ParseMode.MARKDOWN_V2)
    
    return show_monitor_menu(update, context)

def get_monitor_id_to_remove(update: Update, context: CallbackContext):
    tid = update.message.text.strip()
    if tid in MONITOR_TASKS:
        for job in context.job_queue.get_jobs_by_name(f"monitor_{tid}"):
            job.schedule_removal()
        del MONITOR_TASKS[tid]
        save_monitor_tasks()
        update.message.reply_text(f"ğŸ—‘ï¸ ä»»åŠ¡ `{tid}` å·²åœæ­¢å¹¶ç§»é™¤ã€‚", parse_mode=ParseMode.MARKDOWN_V2)
    else:
        update.message.reply_text("âŒ ä»»åŠ¡IDä¸å­˜åœ¨ã€‚")
    return show_monitor_menu(update, context)

def get_monitor_id_to_config(update: Update, context: CallbackContext):
    tid = update.message.text.strip()
    if tid not in MONITOR_TASKS:
        update.message.reply_text("âŒ ä»»åŠ¡IDä¸å­˜åœ¨ã€‚è¯·é‡æ–°è¾“å…¥ã€‚")
        return SETTINGS_STATE_GET_MONITOR_ID_TO_CONFIG
    context.user_data['config_monitor_id'] = tid
    task = MONITOR_TASKS[tid]
    current_threshold = task.get('notification_threshold', 5000)
    update.message.reply_text(f"æ­£åœ¨é…ç½®ä»»åŠ¡ `{tid}`ã€‚\nå½“å‰é€šçŸ¥é˜ˆå€¼ä¸º: *{current_threshold}*ã€‚\n\nè¯·è¾“å…¥æ–°çš„é˜ˆå€¼ \(æ•°å­—\):", parse_mode=ParseMode.MARKDOWN_V2)
    return SETTINGS_STATE_GET_MONITOR_THRESHOLD

def get_monitor_threshold(update: Update, context: CallbackContext):
    try:
        threshold = int(update.message.text.strip())
        if threshold < 0: raise ValueError
        tid = context.user_data.pop('config_monitor_id')
        MONITOR_TASKS[tid]['notification_threshold'] = threshold
        save_monitor_tasks()
        update.message.reply_text(f"âœ… ä»»åŠ¡ `{tid}` çš„é€šçŸ¥é˜ˆå€¼å·²æ›´æ–°ä¸º *{threshold}*ã€‚", parse_mode=ParseMode.MARKDOWN_V2)
    except (ValueError, KeyError):
        update.message.reply_text("âŒ æ— æ•ˆè¾“å…¥ã€‚è¯·è¾“å…¥ä¸€ä¸ªéè´Ÿæ•´æ•°ã€‚")
        return SETTINGS_STATE_GET_MONITOR_THRESHOLD
    return show_monitor_menu(update, context)


# --- /allfofa Command Logic ---
def start_allfofa_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text(f"ğŸšš æ­£åœ¨ä¸ºæŸ¥è¯¢ `{escape_markdown_v2(query_text)}` å‡†å¤‡æµ·é‡æ•°æ®è·å–ä»»åŠ¡\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    
    # v10.9.5 FIX: Set min_level=1 for /allfofa pre-check to ensure a VIP key is used.
    data, used_key, _, _, used_proxy, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_next_data(key, query_text, page_size=10000, proxy_session=proxy_session),
        min_level=1
    )

    if error:
        msg.edit_text(f"âŒ æŸ¥è¯¢é¢„æ£€å¤±è´¥: {escape_markdown_v2(error)}", parse_mode=ParseMode.MARKDOWN_V2)
        return ConversationHandler.END
        
    total_size = data.get('size', 0)
    if total_size == 0:
        msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚")
        return ConversationHandler.END

    initial_results = data.get('results', [])
    initial_next_id = data.get('next')

    context.user_data['query'] = query_text
    context.user_data['total_size'] = total_size
    context.user_data['chat_id'] = update.effective_chat.id
    context.user_data['start_key'] = used_key
    context.user_data['initial_results'] = initial_results
    context.user_data['initial_next_id'] = initial_next_id
    # v10.9.4 FIX: Lock the proxy session for the background job.
    context.user_data['proxy_session'] = used_proxy

    keyboard = [
        [InlineKeyboardButton(f"â™¾ï¸ å…¨éƒ¨è·å– ({total_size}æ¡)", callback_data='allfofa_limit_none')],
        [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='allfofa_limit_cancel')]
    ]
    msg.edit_text(
        f"âœ… æŸ¥è¯¢é¢„æ£€æˆåŠŸï¼Œå…±å‘ç° {total_size} æ¡ç»“æœã€‚\n\n"
        "è¯·è¾“å…¥æ‚¨å¸Œæœ›è·å–çš„æ•°é‡ä¸Šé™ (ä¾‹å¦‚: 50000)ï¼Œæˆ–é€‰æ‹©å…¨éƒ¨è·å–ã€‚",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )
    return QUERY_STATE_ALLFOFA_GET_LIMIT

def allfofa_get_limit(update: Update, context: CallbackContext):
    limit = None
    query = update.callback_query
    
    if query:
        query.answer()
        if query.data == 'allfofa_limit_cancel':
            query.message.edit_text("æ“ä½œå·²å–æ¶ˆ.")
            return ConversationHandler.END
        msg_target = query.message
    else:
        try:
            limit = int(update.message.text.strip())
            assert limit > 0
        except (ValueError, AssertionError):
            update.message.reply_text("âŒ æ— æ•ˆçš„æ•°å­—ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚")
            return QUERY_STATE_ALLFOFA_GET_LIMIT
        msg_target = update.message

    context.user_data['limit'] = limit
    msg_target.reply_text(f"âœ… ä»»åŠ¡å·²æäº¤ï¼\nå°†ä½¿ç”¨ `next` æ¥å£è·å–æ•°æ® (ä¸Šé™: {limit or 'æ— '})...")
    start_download_job(context, run_allfofa_download_job, context.user_data)
    if query:
        msg_target.delete()
    return ConversationHandler.END

def run_allfofa_download_job(context: CallbackContext):
    """
    æ™ºèƒ½å‰¥ç¦»ä¸‹è½½å™¨ (Smart Peeling + Time Slicing)
    æ ¸å¿ƒç­–ç•¥: 
    1. å¾ªç¯æ£€æµ‹å½“å‰Queryçš„æ•°æ®é‡ã€‚
    2. >10000: å– Top1 å›½å®¶ï¼Œæ‹†åˆ†ä¸º Slice (è¯¥å›½å®¶) å’Œ Remaining (éè¯¥å›½å®¶)ã€‚
       å¯¹ Slice ä½¿ç”¨ Time Traceback æš´åŠ›ä¸‹è½½ã€‚
       å¯¹ Remaining è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯ã€‚
    3. <10000: ç›´æ¥æ™®é€šç¿»é¡µä¸‹è½½ã€‚
    """
    job_data = context.job.context
    bot, chat_id = context.bot, job_data['chat_id']
    limit = job_data.get('limit')
    
    # åŸå§‹æŸ¥è¯¢
    original_query = job_data['query']
    
    # ä½¿ç”¨é”å®šçš„ Key å’Œ Proxy Session (ä» allfofa command åˆå§‹åŒ–ä¼ è¿‡æ¥çš„)
    current_key = job_data.get('start_key') 
    proxy_session = job_data.get('proxy_session')

    if not current_key:
        bot.send_message(chat_id, "âŒ å†…éƒ¨é”™è¯¯ï¼šä»»åŠ¡ä¸Šä¸‹æ–‡ä¸¢å¤± Key ä¿¡æ¯ã€‚")
        return

    # è¾“å‡ºæ–‡ä»¶åç®¡ç†
    output_filename = generate_filename_from_query(original_query, prefix="smart_all")
    cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
    
    # ç”¨äºæ˜¾ç¤ºçš„è¿›åº¦æ›´æ–°
    msg = bot.send_message(chat_id, "ğŸš€ æ™ºèƒ½å‰¥ç¦»å¼•æ“å·²å¯åŠ¨...\næ­£åœ¨åˆ†ææ•°æ®åˆ†å¸ƒ...")
    stop_flag = f'stop_job_{chat_id}'
    
    current_query_scope = original_query
    collected_results = set() # ä¸ºäº†æœ€åå»é‡ (æµ·é‡æ•°æ®å†…å­˜æ˜¯ä¸ªé—®é¢˜ï¼Œä½†å¯¹äºset stré€šå¸¸è¿˜èƒ½æ¥å—ï¼Œå¦‚æœç™¾ä¸‡çº§è€ƒè™‘è½ç›˜å»é‡)
    
    loop_count = 0
    start_time = time.time()
    last_ui_update = 0

    try:
        while True:
            loop_count += 1
            if context.bot_data.get(stop_flag):
                msg.edit_text("ğŸŒ€ ä»»åŠ¡å·²æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¸­æ­¢...")
                break
                
            if limit and len(collected_results) >= limit:
                break

            # 1. ä¼°ç®—å½“å‰ Scope å¤§å°
            data_size_chk, error = fetch_fofa_data(current_key, current_query_scope, page_size=1, fields="host", proxy_session=proxy_session)
            if error: 
                msg.edit_text(f"âŒ ä¾¦æŸ¥å¤±è´¥: {error}")
                break
            
            scope_size = data_size_chk.get('size', 0)
            
            # --- é˜¶æ®µ A: å°æ•°æ®é‡ç›´æ¥åå™¬ ---
            if scope_size <= 10000: # å°äº1ä¸‡ï¼Œä¸€é”…ç«¯
                if loop_count == 1: 
                    msg.edit_text(f"ğŸ” æ•°æ®é‡ ({scope_size}) å°äºå•æ¬¡é™åˆ¶ï¼Œç›´æ¥ä¸‹è½½...")
                
                # æ™®é€šç¿»é¡µè·å– (Normal Page Iteration)
                pages = (scope_size + 9999) // 10000
                for p in range(1, pages + 1):
                    # è·å–
                    d, e = fetch_fofa_data(current_key, current_query_scope, page=p, page_size=10000, fields="host", proxy_session=proxy_session)
                    if not e and d.get('results'):
                        collected_results.update([r for r in d.get('results') if isinstance(r, str) and ':' in r])
                    
                    # è¿›åº¦UI
                    if time.time() - last_ui_update > 3:
                        msg.edit_text(f"ğŸ“¥ ç›´æ¥ä¸‹è½½ä¸­... (å·²æ”¶å½•: {len(collected_results)})")
                        last_ui_update = time.time()
                        
                break # å½“å‰å‰©ä½™çš„æ‰€æœ‰éƒ½åœ¨è¿™ä¸€è½®è¢«æ‹¿èµ°äº†ï¼Œå¤§å¾ªç¯ç»“æŸ

            # --- é˜¶æ®µ B: å¤§æ•°æ®é‡ç©ºé—´å‰¥ç¦» (Country Slicing) ---
            # è·å– Top1 å›½å®¶
            stats_data, e = fetch_fofa_stats(current_key, current_query_scope, proxy_session=proxy_session)
            if e: 
                msg.edit_text(f"âŒ èšåˆåˆ†æå¤±è´¥: {e}")
                break
            
            aggs = stats_data.get("aggs", stats_data)
            countries = aggs.get("countries", [])
            
            if not countries:
                # æç«¯æƒ…å†µï¼šæŸ¥åˆ°äº†Sizeä½†æ²¡æœ‰Statså›½å®¶ï¼Ÿå¯èƒ½æ˜¯IPç±»å‹ã€‚
                # å¼ºåˆ¶è¿›å…¥æ—¶é—´åˆ‡ç‰‡æ¨¡å¼ (Blind Traceback)
                top_country_code = None
            else:
                top_country_code = countries[0].get('name') # e.g., "US" or "CN"
            
            # æ„é€ åˆ‡ç‰‡æŸ¥è¯¢
            if top_country_code:
                slice_query = f'({current_query_scope}) && country="{top_country_code}"'
                # å‰©ä½™éƒ¨åˆ† = å½“å‰Scope && ä¸ç­‰äº Top1
                next_round_query = f'({current_query_scope}) && country!="{top_country_code}"'
                slice_desc = f"å›½å®¶={top_country_code}"
            else:
                # å¦‚æœæ²¡æ³•æŒ‰å›½å®¶åˆ†ï¼Œé‚£å°±æ•´ä¸ªå½“åšä¸€å—è‚‰ï¼Œå°è¯•ç¡¬åˆ‡ (fallback to Time Trace on whole query)
                slice_query = current_query_scope
                next_round_query = None # æ²¡æœ‰ä¸‹ä¸€è½®äº†ï¼Œè¿™æ˜¯æœ€åä¸€æ
                slice_desc = "å…¨éƒ¨å‰©ä½™æ•°æ®"

            # å¯¹ Slice ä½¿ç”¨æ·±åº¦è¿½æº¯ä¸‹è½½ (Time Peeling)
            # ç”¨æˆ·æ ¸å¿ƒç­–ç•¥ï¼šå¤ç”¨æ·±åº¦è¿½æº¯ï¼Œåˆ©ç”¨æ—¶é—´è½´æŠŠè¿™ä¸ªå·¨å¤§çš„ slice æ‰’ä¸‹æ¥
            trace_count_added = 0
            iterator = iter_fofa_traceback(current_key, slice_query, limit=limit, proxy_session=proxy_session)
            
            for batch in iterator:
                if context.bot_data.get(stop_flag): break
                
                # æ‰¹é‡æ·»åŠ 
                valid_items = [item[0] for item in batch if item and isinstance(item, list) and len(item)>0]
                new_items_count = 0
                for item in valid_items:
                    if item not in collected_results:
                        collected_results.add(item)
                        new_items_count += 1
                        
                trace_count_added += new_items_count
                
                if time.time() - last_ui_update > 3:
                    try:
                        prog_bar = create_progress_bar(min(len(collected_results) / (limit or (len(collected_results)+100000)) * 100, 100))
                        # ä¿®æ”¹ç‚¹ï¼šå¯¹ slice_desc ä½¿ç”¨ escape_markdown_v2
                        msg.edit_text(
                            f"âœ‚ï¸ *æ­£åœ¨å‰¥ç¦»æ•°æ®å—:* `{escape_markdown_v2(slice_desc)}`\n"
                            f"ğŸ“‰ ç­–ç•¥: æ—¶é—´è½´é™ç»´æ‰“å‡» (Time Trace)\n"
                            f"{prog_bar} æ€»æ•°: {len(collected_results)}\n"
                            f"\\(æœ¬è½®æ–°å¢: {trace_count_added}\\)", # å»ºè®®ï¼šè¿™é‡Œçš„æ‹¬å·ä¹Ÿé¡ºæ‰‹è½¬ä¹‰ä¸€ä¸‹ï¼Œè™½ç„¶ä¸æ˜¯å¿…é¡»
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                    except Exception: pass
                    last_ui_update = time.time()
                
                if limit and len(collected_results) >= limit: break
            
            if not next_round_query or context.bot_data.get(stop_flag):
                break
                
            # å‡†å¤‡è¿›å…¥ä¸‹ä¸€è½®ï¼Œå¤„ç†è¢«æ’é™¤äº† Top1 åçš„å‰©ä½™ä¸–ç•Œ
            current_query_scope = next_round_query
            # é˜²æ­¢æ— é™æ­»å¾ªç¯ä¿æŠ¤ (ä¾‹å¦‚ Stats è¿”å›ç©ºä½†Size > 0)
            if loop_count > 50:
                msg.edit_text("âš ï¸ è­¦å‘Šï¼šæ™ºèƒ½å‰¥ç¦»å¾ªç¯æ¬¡æ•°è¿‡å¤šï¼Œè‡ªåŠ¨åœæ­¢ä»¥é˜²æ­»é”ã€‚")
                break

    except Exception as e:
        logger.error(f"Smart download fatal error: {e}", exc_info=True)
        msg.edit_text(f"âŒ ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return
    
    # ç»“æœäº¤ä»˜
    final_limit_msg = ""
    if limit and len(collected_results) >= limit: final_limit_msg = f" (å·²è¾¾ä¸Šé™ {limit})"
    
    if collected_results:
        # æ’åºå¹¶å†™å…¥æ–‡ä»¶
        sorted_results = sorted(list(collected_results))
        with open(cache_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(sorted_results))
            
        final_caption = f"âœ… *æµ·é‡ä¸‹è½½å®Œæˆ*\n\nğŸ¯ åŸå§‹æŸ¥è¯¢: `{escape_markdown_v2(original_query)}`\nğŸ”¢ æœ€ç»ˆè·å–: *{len(collected_results)}* æ¡{escape_markdown_v2(final_limit_msg)}\nâ± è€—æ—¶: {int(time.time()-start_time)}s"
        send_file_safely(context, chat_id, cache_path, caption=final_caption, parse_mode=ParseMode.MARKDOWN_V2)
        upload_and_send_links(context, chat_id, cache_path)
        
        # æœ¬åœ°è®°å½•æ›´æ–°
        cache_entry = {'file_path': cache_path, 'result_count': len(collected_results)}
        add_or_update_query(original_query, cache_entry)
        
        offer_post_download_actions(context, chat_id, original_query)
        msg.delete() # åˆ æ‰è¿›åº¦æ¡
        
    else:
        msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡ç»“æŸï¼Œæœªæ”¶é›†åˆ°æœ‰æ•ˆæ•°æ®ã€‚")
    
    context.bot_data.pop(stop_flag, None)

# --- èœå•æŸ¥è¯¢å¤„ç†å™¨ (v10.9.6) ---
def prompt_for_query(update: Update, context: CallbackContext) -> int:
    """è¦æ±‚ç”¨æˆ·ä¸ºèœå•å‘½ä»¤è¾“å…¥æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚"""
    button_text = update.message.text
    command_map = { "å¸¸è§„æœç´¢": "/kkfofa", "æµ·é‡æœç´¢": "/allfofa", "æ‰¹é‡å¯¼å‡º": "/batch" }
    command = command_map.get(button_text)
    if not command: return ConversationHandler.END
    context.user_data['menu_command'] = command
    update.message.reply_text(f"è¯·è¾“å…¥ `{command}` çš„æŸ¥è¯¢è¯­å¥:")
    return STATE_AWAITING_QUERY

def prompt_for_host(update: Update, context: CallbackContext) -> int:
    """è¦æ±‚ç”¨æˆ·ä¸ºä¸»æœºå‘½ä»¤è¾“å…¥ä¸»æœºå­—ç¬¦ä¸²ã€‚"""
    context.user_data['menu_command'] = '/host'
    update.message.reply_text("è¯·è¾“å…¥è¦æŸ¥è¯¢çš„ä¸»æœº (IPæˆ–åŸŸå):")
    return STATE_AWAITING_HOST

def run_query_from_menu(update: Update, context: CallbackContext):
    """ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ–‡æœ¬è¿è¡ŒæŸ¥è¯¢å‘½ä»¤ã€‚"""
    command = context.user_data.pop('menu_command', None)
    query_text = update.message.text
    context.args = query_text.split()

    if command == '/batch':
        return batch_command(update, context)
    elif command in ['/kkfofa', '/allfofa']:
        return query_entry_point(update, context)
    return ConversationHandler.END

def run_host_from_menu(update: Update, context: CallbackContext):
    """ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ–‡æœ¬è¿è¡Œä¸»æœºå‘½ä»¤ã€‚"""
    context.user_data.pop('menu_command', None)
    host_text = update.message.text
    context.args = host_text.split()
    
    # host_command å¸¦æœ‰ admin_only è£…é¥°å™¨
    host_command(update, context)
    return ConversationHandler.END


# --- /preview å‘½ä»¤ (v10.9.7) ---
def _build_preview_message(context: CallbackContext, page: int):
    """æ„å»ºé¢„è§ˆæ¶ˆæ¯æ–‡æœ¬å’ŒæŒ‰é’®ã€‚"""
    results = context.user_data.get('preview_results', [])
    total_pages = context.user_data.get('preview_total_pages', 0)
    query_text = context.user_data.get('preview_query', 'N/A')

    if not results:
        return "æ²¡æœ‰å¯ä¾›é¢„è§ˆçš„ç»“æœã€‚", None

    start_index = (page - 1) * PREVIEW_PAGE_SIZE
    end_index = start_index + PREVIEW_PAGE_SIZE
    page_results = results[start_index:end_index]
    
    # [ip, port, title]
    message_parts = [f"ğŸ“„ *é¢„è§ˆ: `{escape_markdown_v2(query_text)}`* \\(ç¬¬ {page}/{total_pages} é¡µ\\)\n"]
    for item in page_results:
        ip, port, title = item[0], item[1], item[2]
        title_str = escape_markdown_v2(title.strip()) if title else "_æ— æ ‡é¢˜_"
        # ä¿®æ”¹ç‚¹ï¼šå°† - ä¿®æ”¹ä¸º \-
        message_parts.append(f"`{escape_markdown_v2(ip)}:{port}` \\- {title_str}")
    
    message = "\n".join(message_parts)

    keyboard_row = []
    if page > 1:
        keyboard_row.append(InlineKeyboardButton("â¬…ï¸ ä¸Šä¸€é¡µ", callback_data="preview_prev"))
    keyboard_row.append(InlineKeyboardButton("âŒ å…³é—­", callback_data="preview_close"))
    if page < total_pages:
        keyboard_row.append(InlineKeyboardButton("ä¸‹ä¸€é¡µ â¡ï¸", callback_data="preview_next"))
    
    return message, InlineKeyboardMarkup([keyboard_row])

def preview_command(update: Update, context: CallbackContext) -> int:
    """/preview å’Œ /p å‘½ä»¤çš„å…¥å£ç‚¹ã€‚"""
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/preview <FOFA æŸ¥è¯¢è¯­å¥>`\næ­¤å‘½ä»¤ç”¨äºå¿«é€Ÿé¢„è§ˆå°‘é‡æ•°æ®ã€‚", parse_mode=ParseMode.MARKDOWN_V2)
        return ConversationHandler.END
        
    query_text = " ".join(context.args)
    msg = update.message.reply_text("â³ æ­£åœ¨è·å–é¢„è§ˆæ•°æ®...")

    def query_logic(key, key_level, proxy_session):
        # è¯·æ±‚50æ¡æ•°æ®ï¼Œå­—æ®µä¸º ip, port, title
        return fetch_fofa_data(key, query_text, page=1, page_size=50, fields="ip,port,title", proxy_session=proxy_session)

    data, _, _, _, _, error = execute_query_with_fallback(query_logic, min_level=0)

    if error:
        msg.edit_text(f"âŒ é¢„è§ˆå¤±è´¥: {error}")
        return ConversationHandler.END

    results = data.get('results', [])
    if not results:
        msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚")
        return ConversationHandler.END

    context.user_data['preview_results'] = results
    context.user_data['preview_query'] = query_text
    context.user_data['preview_page'] = 1
    total_pages = (len(results) - 1) // PREVIEW_PAGE_SIZE + 1
    context.user_data['preview_total_pages'] = total_pages

    message_text, reply_markup = _build_preview_message(context, page=1)
    
    msg.edit_text(
        message_text,
        reply_markup=reply_markup,
        parse_mode=ParseMode.MARKDOWN_V2
    )

    return PREVIEW_STATE_PAGINATE

def preview_page_callback(update: Update, context: CallbackContext):
    """å¤„ç†é¢„è§ˆç¿»é¡µæŒ‰é’®ã€‚"""
    query = update.callback_query
    query.answer()
    
    action = query.data.split('_')[1]
    
    current_page = context.user_data.get('preview_page', 1)
    
    if action == "close":
        query.message.edit_text("é¢„è§ˆå·²å…³é—­ã€‚")
        context.user_data.clear()
        return ConversationHandler.END
        
    elif action == "next":
        new_page = current_page + 1
    elif action == "prev":
        new_page = current_page - 1
    else:
        return PREVIEW_STATE_PAGINATE
        
    total_pages = context.user_data.get('preview_total_pages', 0)
    if not 1 <= new_page <= total_pages:
        return PREVIEW_STATE_PAGINATE

    context.user_data['preview_page'] = new_page
    
    message_text, reply_markup = _build_preview_message(context, page=new_page)
    
    try:
        query.edit_message_text(
            message_text,
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN_V2
        )
    except BadRequest as e:
        if "Message is not modified" not in str(e):
            logger.error(f"ç¼–è¾‘é¢„è§ˆæ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    return PREVIEW_STATE_PAGINATE

# --- ä¸»å‡½æ•°ä¸è°ƒåº¦å™¨ ---
def interactive_setup():
    """Handles the initial interactive setup for the bot."""
    global CONFIG
    print("--- é¦–æ¬¡è¿è¡Œæˆ–é…ç½®ä¸å®Œæ•´ï¼Œè¿›å…¥äº¤äº’å¼è®¾ç½® ---")
    bot_token = input("è¯·è¾“å…¥æ‚¨çš„ Telegram Bot Token (ç•™ç©ºåˆ™é€€å‡º): ").strip()
    if not bot_token:
        return False
    
    admin_id_str = ""
    while not admin_id_str.isdigit():
        admin_id_str = input("è¯·è¾“å…¥æ‚¨çš„ Telegram User ID (ä½œä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜): ").strip()
        if not admin_id_str.isdigit():
            print("é”™è¯¯: User ID å¿…é¡»æ˜¯çº¯æ•°å­—ã€‚")

    admin_id = int(admin_id_str)
    
    CONFIG["bot_token"] = bot_token
    if not CONFIG.get("admins"): # Only set admins if list is empty
        CONFIG["admins"] = [admin_id]

    fofa_keys = []
    if not CONFIG.get("apis"): # Only ask for keys if none are present
        print("è¯·è¾“å…¥æ‚¨çš„ FOFA API Key (è¾“å…¥ç©ºè¡Œç»“æŸ):")
        while True:
            key = input(f"  - Key #{len(fofa_keys) + 1}: ").strip()
            if not key: break
            fofa_keys.append(key)
        CONFIG["apis"] = fofa_keys

    save_config()
    print("âœ… é…ç½®å·²ä¿å­˜åˆ° config.jsonã€‚")
    CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
    return True

def main() -> None:
    global CONFIG
    os.makedirs(FOFA_CACHE_DIR, exist_ok=True)

    if not os.path.exists(CONFIG_FILE) or CONFIG.get("bot_token") == "YOUR_BOT_TOKEN_HERE":
        if not interactive_setup():
            sys.exit(0)

    while True:
        try:
            bot_token = CONFIG.get("bot_token")
            if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE":
                logger.critical("é”™è¯¯: 'bot_token' æœªåœ¨ config.json ä¸­è®¾ç½®!")
                if not interactive_setup():
                    break
                continue

            check_and_classify_keys()
            updater = Updater(token=bot_token, use_context=True, request_kwargs={'read_timeout': 20, 'connect_timeout': 20})
            break  # Break loop if updater is created successfully
        except InvalidToken:
            logger.error("!!!!!! æ— æ•ˆçš„ Bot Token !!!!!!")
            print("å½“å‰é…ç½®çš„ Telegram Bot Token æ— æ•ˆã€‚")
            if not interactive_setup():
                sys.exit(0)
        except Exception as e:
            logger.critical(f"å¯åŠ¨æ—¶å‘ç”Ÿæ— æ³•æ¢å¤çš„é”™è¯¯: {e}")
            sys.exit(1)

    dispatcher = updater.dispatcher
    dispatcher.bot_data['updater'] = updater
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), BotCommand("help", "â“ å‘½ä»¤æ‰‹å†Œ"),
        BotCommand("preview", "ğŸ“„ å¿«é€Ÿé¢„è§ˆ"),
        BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢ (å¸¸è§„)"), BotCommand("allfofa", "ğŸšš èµ„äº§æœç´¢ (æµ·é‡)"),
        BotCommand("host", "ğŸ“¦ ä¸»æœºè¯¦æŸ¥ (æ™ºèƒ½)"), BotCommand("lowhost", "ğŸ”¬ ä¸»æœºé€ŸæŸ¥ (èšåˆ)"),
        BotCommand("stats", "ğŸ“Š å…¨å±€èšåˆç»Ÿè®¡"), BotCommand("batchfind", "ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ (Excel)"),
        BotCommand("batch", "ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º (äº¤äº’å¼)"), BotCommand("batchcheckapi", "ğŸ”‘ æ‰¹é‡éªŒè¯API Key"),
        BotCommand("check", "ğŸ©º ç³»ç»Ÿè‡ªæ£€"), BotCommand("settings", "âš™ï¸ è®¾ç½®èœå•"),
        BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"),
        BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"),
        BotCommand("update", "ğŸ”„ åœ¨çº¿æ›´æ–°è„šæœ¬"), BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
        BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"),
        BotCommand("monitor", "ğŸ“¡ ç›‘æ§é›·è¾¾ (æ·»åŠ /åˆ—è¡¨/åˆ é™¤)"), BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")
    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            SETTINGS_STATE_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            SETTINGS_STATE_ACTION: [
                CallbackQueryHandler(settings_action_handler, pattern=r"^action_"),
                CallbackQueryHandler(show_update_menu, pattern=r"^settings_update"),
                CallbackQueryHandler(show_backup_restore_menu, pattern=r"^settings_backup"),
                CallbackQueryHandler(backup_config_command, pattern=r"^backup_now"),
                CallbackQueryHandler(lambda u,c: restore_config_command(u.callback_query.message, c), pattern=r"^restore_now"),
                CallbackQueryHandler(get_update_url, pattern=r"^update_set_url"),
                CallbackQueryHandler(settings_command, pattern=r"^(update_back|backup_back)"),
            ],
            SETTINGS_STATE_ADMIN_MENU: [CallbackQueryHandler(admin_menu_callback, pattern=r"^admin_")],
            SETTINGS_STATE_GET_ADMIN_ID_TO_ADD: [MessageHandler(Filters.text & ~Filters.command, get_admin_id_to_add)],
            SETTINGS_STATE_GET_ADMIN_ID_TO_REMOVE: [MessageHandler(Filters.text & ~Filters.command, get_admin_id_to_remove)],
            
            # ç›‘æ§è®¾ç½®çŠ¶æ€
            SETTINGS_STATE_MONITOR_MENU: [CallbackQueryHandler(monitor_menu_callback, pattern=r"^monitor_")],
            SETTINGS_STATE_GET_MONITOR_QUERY_TO_ADD: [MessageHandler(Filters.text & ~Filters.command, get_monitor_query_to_add)],
            SETTINGS_STATE_GET_MONITOR_ID_TO_REMOVE: [MessageHandler(Filters.text & ~Filters.command, get_monitor_id_to_remove)],
            SETTINGS_STATE_GET_MONITOR_ID_TO_CONFIG: [MessageHandler(Filters.text & ~Filters.command, get_monitor_id_to_config)],
            SETTINGS_STATE_GET_MONITOR_THRESHOLD: [MessageHandler(Filters.text & ~Filters.command, get_monitor_threshold)],

            SETTINGS_STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            SETTINGS_STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
            SETTINGS_STATE_PRESET_MENU: [CallbackQueryHandler(preset_menu_callback, pattern=r"^preset_")],
            SETTINGS_STATE_GET_PRESET_NAME: [MessageHandler(Filters.text & ~Filters.command, get_preset_name)],
            SETTINGS_STATE_GET_PRESET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_preset_query)],
            SETTINGS_STATE_REMOVE_PRESET: [MessageHandler(Filters.text & ~Filters.command, remove_preset)],
            SETTINGS_STATE_GET_UPDATE_URL: [MessageHandler(Filters.text & ~Filters.command, get_update_url)],
            SETTINGS_STATE_PROXYPOOL_MENU: [CallbackQueryHandler(proxypool_menu_callback, pattern=r"^proxypool_")],
            SETTINGS_STATE_GET_PROXY_ADD: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_add)],
            SETTINGS_STATE_GET_PROXY_REMOVE: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_remove)],
            SETTINGS_STATE_UPLOAD_API_MENU: [CallbackQueryHandler(upload_api_menu_callback, pattern=r"^upload_")],
            SETTINGS_STATE_GET_UPLOAD_URL: [MessageHandler(Filters.text & ~Filters.command, get_upload_url)],
            SETTINGS_STATE_GET_UPLOAD_TOKEN: [MessageHandler(Filters.text & ~Filters.command, get_upload_token)],
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
    )
    query_conv = ConversationHandler(
        entry_points=[ CommandHandler("kkfofa", query_entry_point), CommandHandler("allfofa", query_entry_point), CallbackQueryHandler(query_entry_point, pattern=r"^run_preset_") ],
        states={
            QUERY_STATE_GET_GUEST_KEY: [MessageHandler(Filters.text & ~Filters.command, get_guest_key)],
            QUERY_STATE_ASK_CONTINENT: [CallbackQueryHandler(ask_continent_callback, pattern=r"^continent_")], 
            QUERY_STATE_CONTINENT_CHOICE: [CallbackQueryHandler(continent_choice_callback, pattern=r"^continent_")], 
            QUERY_STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            QUERY_STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            QUERY_STATE_GET_TRACEBACK_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")],
            QUERY_STATE_ALLFOFA_GET_LIMIT: [MessageHandler(Filters.text & ~Filters.command, allfofa_get_limit), CallbackQueryHandler(allfofa_get_limit, pattern=r"^allfofa_limit_")]
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
    )
    batch_conv = ConversationHandler(
        entry_points=[CommandHandler("batch", batch_command)], 
        states={
            BATCH_STATE_SELECT_FIELDS: [CallbackQueryHandler(batch_select_fields_callback, pattern=r"^batchfield_")],
            BATCH_STATE_MODE_CHOICE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            BATCH_STATE_GET_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")]
        },
        fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=600,
    )
    import_conv = ConversationHandler(entry_points=[CommandHandler("import", import_command)], states={IMPORT_STATE_GET_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), get_import_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    stats_conv = ConversationHandler(entry_points=[CommandHandler("stats", stats_command)], states={STATS_STATE_GET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_fofa_stats_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    batchfind_conv = ConversationHandler(entry_points=[CommandHandler("batchfind", batchfind_command)], states={BATCHFIND_STATE_GET_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), get_batch_file_handler)], BATCHFIND_STATE_SELECT_FEATURES: [CallbackQueryHandler(select_batch_features_callback, pattern=r"^batchfeature_")]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    restore_conv = ConversationHandler(entry_points=[CommandHandler("restore", restore_config_command)], states={RESTORE_STATE_GET_FILE: [MessageHandler(Filters.document, receive_config_file)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    scan_conv = ConversationHandler(entry_points=[CallbackQueryHandler(start_scan_callback, pattern=r'^start_scan_')], states={SCAN_STATE_GET_CONCURRENCY: [MessageHandler(Filters.text & ~Filters.command, get_concurrency_callback)], SCAN_STATE_GET_TIMEOUT: [MessageHandler(Filters.text & ~Filters.command, get_timeout_callback)]}, fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=120)
    batch_check_api_conv = ConversationHandler(entry_points=[CommandHandler("batchcheckapi", batch_check_api_command)], states={BATCHCHECKAPI_STATE_GET_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), receive_api_file)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    
    # æ–°å¢é¢„è§ˆåŠŸèƒ½çš„ä¼šè¯å¤„ç†å™¨
    preview_conv = ConversationHandler(
        entry_points=[CommandHandler("preview", preview_command)],
        states={
            PREVIEW_STATE_PAGINATE: [CallbackQueryHandler(preview_page_callback, pattern=r"^preview_")]
        },
        fallbacks=[CommandHandler("cancel", cancel)],
        conversation_timeout=300
    )

    dispatcher.add_handler(CommandHandler("start", start_command)); dispatcher.add_handler(CommandHandler("help", help_command)); dispatcher.add_handler(CommandHandler("host", host_command)); dispatcher.add_handler(CommandHandler("lowhost", lowhost_command)); dispatcher.add_handler(CommandHandler("check", check_command)); dispatcher.add_handler(CommandHandler("stop", stop_all_tasks)); dispatcher.add_handler(CommandHandler("backup", backup_config_command)); dispatcher.add_handler(CommandHandler("history", history_command)); dispatcher.add_handler(CommandHandler("getlog", get_log_command)); dispatcher.add_handler(CommandHandler("shutdown", shutdown_command)); dispatcher.add_handler(CommandHandler("update", update_script_command)); dispatcher.add_handler(CommandHandler("monitor", monitor_command)) # æ³¨å†Œç›‘æ§å‘½ä»¤
    dispatcher.add_handler(InlineQueryHandler(inline_fofa_handler)); 
    
    # --- æ¢å¤ç›‘æ§ä»»åŠ¡ ---
    if MONITOR_TASKS:
        count = 0
        for task_id, task in MONITOR_TASKS.items():
            if task.get('status') == 'active':
                # è®¡ç®—åˆå§‹å»¶è¿Ÿï¼šåˆ†æ•£å¯åŠ¨ï¼Œé¿å…æ´ªå³° (0 - 60s)
                delay = random.randint(5, 60)
                updater.job_queue.run_once(run_monitor_execution_job, delay, context={"task_id": task_id, "is_restore": True}, name=f"monitor_{task_id}")
                count += 1
        logger.info(f"å·²æ¢å¤ {count} ä¸ªç›‘æ§ä»»åŠ¡ã€‚")
    dispatcher.add_handler(settings_conv); dispatcher.add_handler(query_conv); dispatcher.add_handler(batch_conv); dispatcher.add_handler(import_conv); dispatcher.add_handler(stats_conv); dispatcher.add_handler(batchfind_conv); dispatcher.add_handler(restore_conv); dispatcher.add_handler(scan_conv); dispatcher.add_handler(batch_check_api_conv); dispatcher.add_handler(preview_conv)
    
    logger.info(f"ğŸš€ Fofa Bot v10.9 (ç¨³å®šç‰ˆ) å·²å¯åŠ¨...")
    updater.start_polling()
    updater.idle()
    logger.info("Bot has been shut down gracefully.")

if __name__ == "__main__":
    main()
